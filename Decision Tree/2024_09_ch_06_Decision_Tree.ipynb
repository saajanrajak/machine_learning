{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a45996",
   "metadata": {},
   "source": [
    "# Content\n",
    " - what are Decision Trees\n",
    " - when these are useful\n",
    " - How to train, Visualize and make Predication \n",
    " - Regularize Decision Trees\n",
    " - Different techinques Like CART algo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e31f620",
   "metadata": {},
   "source": [
    "**Decision Tree** \n",
    "- Its a machine learning algorithm that can perform both Regression and Classification, plus multioutput tasks too\n",
    "- Capable of fitting complex datasets\n",
    "- It divide data into subsets through series of yes/no question or multiway split(continious).\n",
    "- **Explainiablity** when interpretability is crucial, decision Trees are used since its provide visual and intutive understanding\n",
    "\n",
    "## ----\n",
    "\n",
    "**Most Common Algos For Decision Tree**\n",
    "\n",
    "- **ID3 (Iterative Dichotomiser 3)** uses **Information Gain** to decide which feature to split on at each step\n",
    "   - it can be used only in classification\n",
    "- **CART (Classification and Regressioin Tree** uses **Gini Index** for classification and **Mean Square Error** for regression trees\n",
    "   - as name says it can be used in both regression and classification\n",
    "- **C4.5** - Extension of ID3, also handles missing values. Its uses **Gain Ratio** instead of information gain for better splits\n",
    "   - it can handle both regression and classification \n",
    "- **CHAID (Chi Squared Automatic Interaction Detection)** - uses **CHI-Squared Test** to find the best spilit\n",
    "   - it can both regression and classification. But Generally used for classification\n",
    "\n",
    "\n",
    "## ----\n",
    "**Most Common Advanced Tree based Models**\n",
    "- **Random Forest**: An ensemble method that builds multiple decision trees and averages their predictions to improve performance and robustness.\n",
    "- **Gradient Boosting Machines (GBM)**: Build trees sequentially, with each tree trying to correct the errors of the previous ones.\n",
    "- **XGBoost/Light GBM/CatBoost** : Efficient implementations of gradient boosting algorithms, often used in competitive machine learning\n",
    "   \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e485d0",
   "metadata": {},
   "source": [
    "# 1. Training and Visualizing a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89315e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris(as_frame = True)\n",
    "X_iris = iris.data[['petal length (cm)', 'petal width (cm)']].values\n",
    "\n",
    "y_iris = iris.target\n",
    "print(len(X_iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c32da8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=2, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize tree classifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth = 2, random_state = 42)\n",
    "tree_clf.fit(X_iris, y_iris)  # X and y are here ndimension array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9efbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## installing package via pip install graphviz was not working, conda install its images are rendering now in jupyter notebook\n",
    "# conda remove graphviz\n",
    "# conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad68cdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"351pt\" height=\"314pt\"\n",
       " viewBox=\"0.00 0.00 351.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-310 347,-310 347,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M209.5,-306C209.5,-306 65.5,-306 65.5,-306 59.5,-306 53.5,-300 53.5,-294 53.5,-294 53.5,-235 53.5,-235 53.5,-229 59.5,-223 65.5,-223 65.5,-223 209.5,-223 209.5,-223 215.5,-223 221.5,-229 221.5,-235 221.5,-235 221.5,-294 221.5,-294 221.5,-300 215.5,-306 209.5,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) &lt;= 2.45</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.667</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M105,-179.5C105,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 105,-111.5 105,-111.5 111,-111.5 117,-117.5 117,-123.5 117,-123.5 117,-167.5 117,-167.5 117,-173.5 111,-179.5 105,-179.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110.09,-222.91C102.49,-211.65 94.23,-199.42 86.59,-188.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"89.39,-186 80.89,-179.67 83.59,-189.91 89.39,-186\"/>\n",
       "<text text-anchor=\"middle\" x=\"76.14\" y=\"-200.51\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M286,-187C286,-187 147,-187 147,-187 141,-187 135,-181 135,-175 135,-175 135,-116 135,-116 135,-110 141,-104 147,-104 147,-104 286,-104 286,-104 292,-104 298,-110 298,-116 298,-116 298,-175 298,-175 298,-181 292,-187 286,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.75</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M164.91,-222.91C170.91,-214.01 177.33,-204.51 183.53,-195.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"186.44,-197.27 189.14,-187.02 180.64,-193.35 186.44,-197.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.9\" y=\"-207.86\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#4de88e\" stroke=\"black\" d=\"M196,-68C196,-68 99,-68 99,-68 93,-68 87,-62 87,-56 87,-56 87,-12 87,-12 87,-6 93,0 99,0 99,0 196,0 196,0 202,0 208,-6 208,-12 208,-12 208,-56 208,-56 208,-62 202,-68 196,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.168</text>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.81,-103.73C185.29,-94.97 179.45,-85.7 173.91,-76.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.78,-74.89 168.48,-68.3 170.85,-78.63 176.78,-74.89\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#843de6\" stroke=\"black\" d=\"M331,-68C331,-68 238,-68 238,-68 232,-68 226,-62 226,-56 226,-56 226,-12 226,-12 226,-6 232,0 238,0 238,0 331,0 331,0 337,0 343,-6 343,-12 343,-12 343,-56 343,-56 343,-62 337,-68 331,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.043</text>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241.82,-103.73C247.26,-94.97 253.01,-85.7 258.48,-76.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"261.52,-78.64 263.82,-68.3 255.57,-74.95 261.52,-78.64\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x1066b9240>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we cab visualize the tree using export_graphviz() \n",
    "# by saving the pic with iris_tree_dot\n",
    "\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(tree_clf,\n",
    "               out_file = 'iris_tree.dot',\n",
    "               feature_names  = ['petal length (cm)', 'petal width (cm)'],\n",
    "               class_names = iris.target_names,\n",
    "                rounded = True,\n",
    "                filled = True\n",
    "               )\n",
    "\n",
    "\n",
    "\n",
    "from graphviz import Source\n",
    "\n",
    "Source.from_file('iris_tree.dot')\n",
    "\n",
    "# graphviz is open source graph visualizaton software package\n",
    "# it also include a dot command-line tool to convert .dot files to a variety formats such as pdf, png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a712a",
   "metadata": {},
   "source": [
    "**Decision Tree require very little data prep. In fact you don't require feature scalling or centering at all**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac43c21",
   "metadata": {},
   "source": [
    "**DecisionTreeClassifier user CART Algorthim**\n",
    "\n",
    "**Gini Impurity  ---**\n",
    "\n",
    "- its a meteric to measure how pure is a node\n",
    "- its value lie in range of 0 to 0.5\n",
    "- 0 means **Pure Node** \n",
    "   - If all the instance belongs to the same class\n",
    "   - gini impurity value is zero\n",
    "- **Maximal Impurity** \n",
    "   - for binary classification maximal impurity or gini impurity index - 0.5\n",
    "   - 50% of one class and 50% of another class\n",
    "   - Indicating those nodes as highly impure\n",
    "   \n",
    "- Gini impurity index formula \n",
    "   - gini = 1 - ∑(from i=1 to n) p<sup>2<sup>\n",
    "   - for binary classification gini = 2*p(1-p)\n",
    "      - p_i : randomly selected class belonnging to class i\n",
    "   - let calculate gini index , from above example \n",
    "      - organge color node Gini impurity index = '1 - (50/50)**2 -(0/50)**2 - (0/50)**2' = **0** Pure Node, gini impurity index 0\n",
    "      - green color node Gini impurity index = '1 - (0/54)**2 - (49/54)**2 - (5/54)**2' = **0.168**, near to zero value, good classification\n",
    "    \n",
    "# ----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06c06d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1680384087791495"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (0/54)**2 - (49/54)**2 - (5/54)**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed418c",
   "metadata": {},
   "source": [
    "# 2. Making Predications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78fe48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will help in finding attributes for the tree\n",
    "# help(tree_clf.tree_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6759fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \n",
      " 2\n"
     ]
    }
   ],
   "source": [
    "print(tree_clf.tree_.node_count, '\\n',\n",
    "     \n",
    "     tree_clf.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce3972e",
   "metadata": {},
   "source": [
    "- Decision trees are intuitive, and their decisions are easy to interpret. \n",
    "   - these models are often called **white box models**. \n",
    "- In contrast, random forests and neural networks are generally considered **black box models**\n",
    "   - because they are difficult to explain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d270bb",
   "metadata": {},
   "source": [
    "## 2.1 Estimating Class Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e45648",
   "metadata": {},
   "source": [
    "- A decision Tree can also estimate the probability that an instance belong to a particular class k.\n",
    "- The decision tree first traverses from the root to a leaf node based on the input sample’s feature values and the splitting rules defined at each node.\n",
    "- At the leaf node, it calculates the class probabilities based on the class distribution of the training samples in that node.\n",
    "\n",
    "   - example for above tree, new obs petal length 5 cm, petal width 1.5 cm\n",
    "   - from traversing from root node, it will come to green leaf node (3rd node)\n",
    "   - in training data for this green leaf node , there are total 54 instances, out of which\n",
    "      - 0 are setosa therefore for new obs given above, being setosa is 0%\n",
    "      - 49 are versicolor, then its 49/54 i.e. 90.7% chance being versiocolor\n",
    "      - similariy 9.3% chance for virginica (5/54)\n",
    "      \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a07afd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.907, 0.093]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict_proba([[5,1.5]]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "255cf306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.predict([[5,1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738b5d6a",
   "metadata": {},
   "source": [
    "# 3. CART Training Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e93034",
   "metadata": {},
   "source": [
    "**CART**: Classification and Regression Tree\n",
    "  - CART, a decision tree model, as name says, it can do both Classification and Regression\n",
    "  - it works by continously creating subsets in two group, based on feature values, aiming to create most homogenous set(pure) in terms of class and labels at each step\n",
    "  - CART builds binary decision treee using greedy approcach to split data based on certain criterion\n",
    "      - **Gini Impurity**\n",
    "      - **MSE**\n",
    "  - **Pros**\n",
    "    - its suits on smaller datasets and where interpretability is important\n",
    "    - Its suits when featuers and target variable show non-linear **relationship**\n",
    "    - Non-parametric: It doesn't assume any specific distribution of the data\n",
    "    - Can handle both numerical and categorical variables\n",
    "  - **Cons**\n",
    "    - biased towards majority class\n",
    "    - Prone to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cc690",
   "metadata": {},
   "source": [
    " ## ----\n",
    "  - CART is greedy algorithm, it greedily searches for an optimum split at the top level, then repaeat the process at each subsequent level\n",
    "  - **It doesn't check wheter or not the split will lead to the lowest possible impurity (global minimum) several levels down**\n",
    "  - Finding optimal tree is know to be an **NP complete** problem, it requires O(exp(m)) time, not suitable for smaller dataset.\n",
    "    - NP-complete is a classification in computational complexity theory that refers to problems that are:\n",
    "\n",
    "       - NP (Nondeterministic Polynomial time): The solution to the problem can be verified in polynomial time.\n",
    "       - Complete: As hard as any other problem in NP, meaning that if you could solve one NP-complete problem efficiently, you could solve all NP problems efficiently.\n",
    "       - example: a large jigsaw puzzle, checking whether all the pieces are placed correctly is quick (just verifying it), but finding the correct arrangement might take a lot of time (trial and error, which could take exponentially long)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d0bf5f",
   "metadata": {},
   "source": [
    " \n",
    "## ----\n",
    "\n",
    "**Computional Complexity for CART**\n",
    "   - O(n*m*log2(m))\n",
    "       - n : number of instances\n",
    "       - m : number of features\n",
    "       - example: number of instance 450, and features 12\n",
    "          - log2(12) = 3.585\n",
    "          - O(450 * 12 * 3.585) = O(19359)\n",
    "          - this means in worst secanrio, roughly 19.3k **Computional steps** will be requried this decision tree\n",
    " \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3cd6ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19359.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "450 * 12 * 3.585\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6949e99",
   "metadata": {},
   "source": [
    "## 3.1 Gini Impurity or Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073264ca",
   "metadata": {},
   "source": [
    "- **Both Gini Impurity and Entropy are metrics, used to evalute the split in Decision tree, aiming to measure the purity of the nodes after the split**\n",
    "- in DecisionTreeClassifier, Gini Impurity used by default but we can select entropy impurity measure too \n",
    "\n",
    "\n",
    "**Gini Impurity** \n",
    "  - def: a measure of how often a randomly chosen element would be incorrectly classified if it was randomly labeled according to the distribution of labels in the dataset.\n",
    "  - Gini  =  1− ∑(from i =1, k) p_i**2\n",
    "     - p_i : proportion of class i at particular node\n",
    "     - k: number of classes\n",
    "     - range : 0 (pure node) to 0.5 (for binary classification when classes are evely split)\n",
    "\n",
    "**Entropy Impurity**: It quantifies the amount of disorder or randomness in a system, typically used in decision trees (like ID3 or C4.5) to assess how well a dataset is split by a feature\n",
    "\n",
    "  - High entropy means the data is highly impure or mixed (e.g., equal numbers of different classes).\n",
    "  - Low entropy means the data is more pure or homogenous (e.g., mostly one class)\n",
    "     \n",
    "   - Entropy Formula: (For a binary classification problem)\n",
    "\n",
    "        - Entropy = -(p_1 * log_2(p_1)) - (p_2 * log_2(p_2))\n",
    "        - p_1 and p_2 are the proportions of the two classes\n",
    "        - for multiclass classification, the formula genarlizes to include all class\n",
    "    - Range: **Entropy values range from 0 (pure node) to log_2(k), where k is the number of classes**. \n",
    "        - In binary classification, the maximum entropy is 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1eca11",
   "metadata": {},
   "source": [
    "| **Aspect**       | **Gini Impurity**                                       | **Entropy**                                      |\n",
    "|------------------|---------------------------------------------------------|--------------------------------------------------|\n",
    "| **Formula**      | \\( 1 - \\sum p_i^2 \\)                                    | \\( - \\sum p_i \\log_2(p_i) \\)                     |\n",
    "| **Range**        | 0 (pure) to 0.5 (impure for binary classification)      | 0 (pure) to 1 (impure for binary classification) |\n",
    "| **Computation**  | Slightly faster to compute due to the absence of logs   | Slower to compute due to logarithmic operations   |\n",
    "| **Preference**   | Tends to create larger trees with simpler splits        | Tends to create smaller trees with more complex splits |\n",
    "| **Sensitivity**  | Gini tends to be more sensitive to class distributions  | Entropy can slightly prefer more balanced splits  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84251d65",
   "metadata": {},
   "source": [
    "# 4 Regularization Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12024cb",
   "metadata": {},
   "source": [
    "**Parametric and Non Parametric Model**\n",
    "  - **A non-parametric model** isn't called \"non-parametric\" because it lacks parameters, but rather because the number of parameters is not fixed prior to training.\n",
    "  - Instead, the model structure adapts based on the training data, which allows it to capture more complex patterns and relationships.\n",
    "  - This flexibility allows non-parametric models to:\n",
    "\n",
    "      - Grow in complexity as more data becomes available.\n",
    "      - Fit the data more closely because they aren't confined to a predetermined form or structure.\n",
    "  \n",
    "  - Examples \n",
    "     - k-Nearest Neighbors (k-NN) doesn't have a fixed number of parameters; the number of neighbors k is a hyperparameter, but the structure of the model depends entirely on the data points.\n",
    "     - Decision Trees continue to add more nodes and splits as they process more data, leading to a model structure that is highly dependent on the specific dataset.\n",
    "     \n",
    "     \n",
    "  - **Parametric models** have a predetermined number of parameters, irrespective of the size or complexity of the dataset.\n",
    "      - its degree of freedom is limited, reducing the risk of overfitting (but increasing the risk of underfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696835e5",
   "metadata": {},
   "source": [
    "| **Aspect**           | **Parametric Models**                                | **Non-Parametric Models**                              |\n",
    "|----------------------|------------------------------------------------------|--------------------------------------------------------|\n",
    "| **Assumptions**       | Strong assumptions about the data distribution       | Few or no assumptions about the data distribution      |\n",
    "| **Number of Parameters** | Fixed, regardless of data size                       | Grows with the size of the dataset                      |\n",
    "| **Flexibility**       | Less flexible, prone to underfitting                 | More flexible, can fit complex data                    |\n",
    "| **Training Time**     | Generally faster to train                            | Slower to train, especially on large datasets          |\n",
    "| **Risk of Overfitting** | Lower risk of overfitting                           | Higher risk of overfitting                             |\n",
    "| **Examples**          | Linear regression, logistic regression, Naive Bayes  | k-NN, decision trees, SVM (with kernels), random forests|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d17da",
   "metadata": {},
   "source": [
    "- To avoid overfitting the training data in, we need to restrict the decision's tree freedom during training, this is called **regularization**\n",
    "\n",
    "- The regularization hyperparameters depends on the model/algorithm that used\n",
    "   - there are many algorithm that can do decision tree, their hyperparameters may change.\n",
    "      - there are some common hyperparameter, one **max_depth**, default value is none,in scickit learn, ,means unlimeted depth.\n",
    "      - reducing the depth will regularize the model and thus reduce the risk of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b2647",
   "metadata": {},
   "source": [
    "## ----\n",
    "- **DecisionTreeClassifier**  other parameters to restrict the shape\n",
    "\n",
    "   - max_features : max number of features that are evaluated for splitting at each node\n",
    "   - max_leaf_nodes : max number of leaf nodes\n",
    "   - min_samples_split : minimum number of samples a node must have before it can be split\n",
    "   - min_samples_leaf : min number of samples a leaf node must have to be created\n",
    "   - min_weight_fraction_leaf: same as min_samples_leaf but expressed as a fraction of the total number of wieghted instances\n",
    "      - This parameter is useful when working with imbalanced datasets or when some instances are weighted differently from others.\n",
    "      \n",
    "### - Increasing min_* hyperparameters or reducing max_* hyperparameters will regularize the model.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f40cb94",
   "metadata": {},
   "source": [
    "All algos, first training the decision tree without restrications, \n",
    " - then pruning (deleting) the unneccessary trees\n",
    " - A node whose children are all leaf nodes is considered unneccesary if the purity improvment it provides is not statistically significant\n",
    " - Standard Statistical Test, such as Chi_squared test are used to estimate the probability, that the improvment is purely the result of chance(which is called null hypothesis)\n",
    "    - If this probability, called the p-value, is higher than a given threshold (typically 5%, controlled by a hyperparameter), then the node is considered unnecessary and its children are deleted. \n",
    "    - The pruning continues until all unnecessary nodes have been pruned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8170b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do regularization on decision tree example\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X_moons, y_moons = make_moons(n_samples = 150, noise = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "tree_clf1 = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "tree_clf2 = DecisionTreeClassifier(min_samples_leaf = 5, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37a5fabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf1.fit(X_moons, y_moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "170b62a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(min_samples_leaf=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(min_samples_leaf=5, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf2.fit(X_moons, y_moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ce8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets test result with differnt sampling\n",
    "\n",
    "X_moons_test, y_moons_test = make_moons(n_samples = 1000, noise = 0.2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ee6d705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898\n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "print(tree_clf1.score(X_moons_test, y_moons_test))\n",
    "print(tree_clf2.score(X_moons_test, y_moons_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c398c",
   "metadata": {},
   "source": [
    "- we need to do cross validation score, one sample may lie, here regularized tree perform better. but not always true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bbd439",
   "metadata": {},
   "source": [
    "# 5. Regression with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76780698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets build a regression tree with dt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "X_quad = np.random.rand(200, 1) - 0.5 # a single random input feature \n",
    "y_quad = X_quad ** 2 + 0.025 * np.random.randn(200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cc9d1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth = 2, random_state =42)\n",
    "tree_reg.fit(X_quad, y_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb1fbb6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"666pt\" height=\"269pt\"\n",
       " viewBox=\"0.00 0.00 666.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-265 662,-265 662,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f6d6be\" stroke=\"black\" d=\"M392,-261C392,-261 265,-261 265,-261 259,-261 253,-255 253,-249 253,-249 253,-205 253,-205 253,-199 259,-193 265,-193 265,-193 392,-193 392,-193 398,-193 404,-199 404,-205 404,-205 404,-249 404,-249 404,-255 398,-261 392,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X_quad &lt;= &#45;0.303</text>\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.006</text>\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 200</text>\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.088</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#eb9d65\" stroke=\"black\" d=\"M308,-157C308,-157 181,-157 181,-157 175,-157 169,-151 169,-145 169,-145 169,-101 169,-101 169,-95 175,-89 181,-89 181,-89 308,-89 308,-89 314,-89 320,-95 320,-101 320,-101 320,-145 320,-145 320,-151 314,-157 308,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X_quad &lt;= &#45;0.408</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 44</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.172</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301.23,-192.88C293.97,-184.07 286.03,-174.43 278.46,-165.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.98,-162.79 271.92,-157.3 275.58,-167.24 280.98,-162.79\"/>\n",
       "<text text-anchor=\"middle\" x=\"269.51\" y=\"-178.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#fae6d7\" stroke=\"black\" d=\"M477,-157C477,-157 350,-157 350,-157 344,-157 338,-151 338,-145 338,-145 338,-101 338,-101 338,-95 344,-89 350,-89 350,-89 477,-89 477,-89 483,-89 489,-95 489,-101 489,-101 489,-145 489,-145 489,-151 483,-157 477,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X_quad &lt;= 0.272</text>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 156</text>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.065</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M356.1,-192.88C363.45,-184.07 371.47,-174.43 379.14,-165.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"382.04,-167.22 385.75,-157.3 376.66,-162.74 382.04,-167.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"388.01\" y=\"-178.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M139,-53C139,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 139,0 139,0 145,0 151,-6 151,-12 151,-12 151,-41 151,-41 151,-47 145,-53 139,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.213</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M185.39,-88.95C167.48,-78.93 147.89,-67.98 130.27,-58.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131.69,-54.91 121.26,-53.09 128.28,-61.02 131.69,-54.91\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#f0b489\" stroke=\"black\" d=\"M308,-53C308,-53 181,-53 181,-53 175,-53 169,-47 169,-41 169,-41 169,-12 169,-12 169,-6 175,0 181,0 181,0 308,0 308,0 314,0 320,-6 320,-12 320,-12 320,-41 320,-41 320,-47 314,-53 308,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.138</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.5,-88.95C244.5,-80.72 244.5,-71.85 244.5,-63.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"248,-63.24 244.5,-53.24 241,-63.24 248,-63.24\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M477,-53C477,-53 350,-53 350,-53 344,-53 338,-47 338,-41 338,-41 338,-12 338,-12 338,-6 344,0 350,0 350,0 477,0 477,0 483,0 489,-6 489,-12 489,-12 489,-41 489,-41 489,-47 483,-53 477,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 110</text>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.028</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M413.5,-88.95C413.5,-80.72 413.5,-71.85 413.5,-63.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"417,-63.24 413.5,-53.24 410,-63.24 417,-63.24\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#edaa79\" stroke=\"black\" d=\"M646,-53C646,-53 519,-53 519,-53 513,-53 507,-47 507,-41 507,-41 507,-12 507,-12 507,-6 513,0 519,0 519,0 646,0 646,0 652,0 658,-6 658,-12 658,-12 658,-41 658,-41 658,-47 652,-53 646,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"582.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n",
       "<text text-anchor=\"middle\" x=\"582.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n",
       "<text text-anchor=\"middle\" x=\"582.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.154</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M472.61,-88.95C490.52,-78.93 510.11,-67.98 527.73,-58.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"529.72,-61.02 536.74,-53.09 526.31,-54.91 529.72,-61.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x14401a530>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Export the tree to a dot file\n",
    "export_graphviz(\n",
    "    tree_reg,\n",
    "    out_file=\"tree_reg_ex_1.dot\",\n",
    "    feature_names=['X_quad'],  # The name of the input feature\n",
    "    rounded=True,\n",
    "    filled=True\n",
    ")\n",
    "\n",
    "# Step 4: Visualize the tree using Graphviz\n",
    "Source.from_file('tree_reg_ex_1.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5333963",
   "metadata": {},
   "source": [
    "- This tree looks very similar to the classification tree you built earlier. The main difference is that instead of predicting a class in each node, it predicts a value. \n",
    "\n",
    "- For example, suppose you want to make a prediction for a new instance with x1 = 0.2. \n",
    "- The root node asks whether x1 ≤ -0.303. \n",
    "   - Since it is not, the algorithm goes to the right child node, \n",
    "   - which asks whether x1 ≤ 0.272. \n",
    "   - Since it is, the algorithm goes to the left child node. \n",
    "   - This is a leaf node, and it predicts value=0.028. \n",
    "   - This prediction is the average target value of the 110 training instances associated with this leaf node,\n",
    "   - and it results in  squared error equal to 0.001 over these 110 instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1493ae81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"666pt\" height=\"269pt\"\n",
       " viewBox=\"0.00 0.00 666.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-265 662,-265 662,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f6d6be\" stroke=\"black\" d=\"M392,-261C392,-261 265,-261 265,-261 259,-261 253,-255 253,-249 253,-249 253,-205 253,-205 253,-199 259,-193 265,-193 265,-193 392,-193 392,-193 398,-193 404,-199 404,-205 404,-205 404,-249 404,-249 404,-255 398,-261 392,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X_quad &lt;= &#45;0.303</text>\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.006</text>\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 200</text>\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.088</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#eb9d65\" stroke=\"black\" d=\"M308,-157C308,-157 181,-157 181,-157 175,-157 169,-151 169,-145 169,-145 169,-101 169,-101 169,-95 175,-89 181,-89 181,-89 308,-89 308,-89 314,-89 320,-95 320,-101 320,-101 320,-145 320,-145 320,-151 314,-157 308,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X_quad &lt;= &#45;0.408</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 44</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.172</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301.23,-192.88C293.97,-184.07 286.03,-174.43 278.46,-165.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.98,-162.79 271.92,-157.3 275.58,-167.24 280.98,-162.79\"/>\n",
       "<text text-anchor=\"middle\" x=\"269.51\" y=\"-178.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#fae6d7\" stroke=\"black\" d=\"M477,-157C477,-157 350,-157 350,-157 344,-157 338,-151 338,-145 338,-145 338,-101 338,-101 338,-95 344,-89 350,-89 350,-89 477,-89 477,-89 483,-89 489,-95 489,-101 489,-101 489,-145 489,-145 489,-151 483,-157 477,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X_quad &lt;= 0.272</text>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.005</text>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 156</text>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.065</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M356.1,-192.88C363.45,-184.07 371.47,-174.43 379.14,-165.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"382.04,-167.22 385.75,-157.3 376.66,-162.74 382.04,-167.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"388.01\" y=\"-178.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M139,-53C139,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 139,0 139,0 145,0 151,-6 151,-12 151,-12 151,-41 151,-41 151,-47 145,-53 139,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n",
       "<text text-anchor=\"middle\" x=\"75.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.213</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M185.39,-88.95C167.48,-78.93 147.89,-67.98 130.27,-58.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131.69,-54.91 121.26,-53.09 128.28,-61.02 131.69,-54.91\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#f0b489\" stroke=\"black\" d=\"M308,-53C308,-53 181,-53 181,-53 175,-53 169,-47 169,-41 169,-41 169,-12 169,-12 169,-6 175,0 181,0 181,0 308,0 308,0 314,0 320,-6 320,-12 320,-12 320,-41 320,-41 320,-47 314,-53 308,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.138</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M244.5,-88.95C244.5,-80.72 244.5,-71.85 244.5,-63.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"248,-63.24 244.5,-53.24 241,-63.24 248,-63.24\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M477,-53C477,-53 350,-53 350,-53 344,-53 338,-47 338,-41 338,-41 338,-12 338,-12 338,-6 344,0 350,0 350,0 477,0 477,0 483,0 489,-6 489,-12 489,-12 489,-41 489,-41 489,-47 483,-53 477,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.001</text>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 110</text>\n",
       "<text text-anchor=\"middle\" x=\"413.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.028</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M413.5,-88.95C413.5,-80.72 413.5,-71.85 413.5,-63.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"417,-63.24 413.5,-53.24 410,-63.24 417,-63.24\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#edaa79\" stroke=\"black\" d=\"M646,-53C646,-53 519,-53 519,-53 513,-53 507,-47 507,-41 507,-41 507,-12 507,-12 507,-6 513,0 519,0 519,0 646,0 646,0 652,0 658,-6 658,-12 658,-12 658,-41 658,-41 658,-47 652,-53 646,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"582.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">squared_error = 0.002</text>\n",
       "<text text-anchor=\"middle\" x=\"582.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n",
       "<text text-anchor=\"middle\" x=\"582.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.154</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M472.61,-88.95C490.52,-78.93 510.11,-67.98 527.73,-58.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"529.72,-61.02 536.74,-53.09 526.31,-54.91 529.72,-61.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x14401a2f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_graphviz(\n",
    "    tree_reg,\n",
    "    out_file=\"tree_reg_mse.dot\",\n",
    "    feature_names=[\"X_quad\"],\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "\n",
    "# Visualize the tree using Graphviz\n",
    "Source.from_file(\"tree_reg_mse.dot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85efe99f",
   "metadata": {},
   "source": [
    "- **Cost function for CART**\n",
    "    - Classification Trees: Use Gini impurity or Entropy to determine the best splits based on class distribution.\n",
    "    - Regression Trees: Use Mean Squared Error to evaluate the quality of splits based on target variable values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbf60c",
   "metadata": {},
   "source": [
    "# 6. Senstivity to Axis Orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f501084c",
   "metadata": {},
   "source": [
    "- decision trees can be sensitive to the orientation of the data. \n",
    "- This sensitivity arises because decision trees make splits based on the feature values along the axes of the feature space. \n",
    "- Here are some points to consider regarding changing the orientation of the data to improve decision tree performance:\n",
    "   - Feature Scaling and Transformation:\n",
    "   - PCA\n",
    "   - Feature Engineering:\n",
    "   - Using Ensemble Methods\n",
    "   - Using Cross validation\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea8dbce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()), ('pca', PCA())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets build a pipline that scales the data and rotate it using PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pca_pipeline = make_pipeline(StandardScaler(),\n",
    "                            PCA())\n",
    "\n",
    "pca_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1a50256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=2, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_iris_rotated = pca_pipeline.fit_transform(X_iris)\n",
    "tree_clf_pca = DecisionTreeClassifier(random_state = 42, max_depth = 2)\n",
    "\n",
    "tree_clf_pca.fit(X_iris_rotated, y_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09065770",
   "metadata": {},
   "source": [
    "# 7. Decision Tree have a high variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd930c5",
   "metadata": {},
   "source": [
    "- DT have high variance,\n",
    "- small changes to the hyperparameters or to the data may produce very different models\n",
    "- the training algorithm used by Scikit-Learn is stochastic—it randomly selects the set of features to evaluate at each node—even retraining the same decision tree on the exact same data may produce a very different model\n",
    "\n",
    "## -----\n",
    "\n",
    "- Luckily, by averaging predictions over many trees, it’s possible to reduce variance significantly. \n",
    "- Such an ensemble of trees is called a random forest,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ad30b",
   "metadata": {},
   "source": [
    "## Happy Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
