{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa21d7e",
   "metadata": {},
   "source": [
    "# 1. Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea9f8a",
   "metadata": {},
   "source": [
    "- Understanding Classification\n",
    "- Solving MNIST Classification Problem\n",
    "- Date : 16th Sep 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf41300",
   "metadata": {},
   "source": [
    "# 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa66cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading MNIST Data\n",
    "# set of 70k small images of digits underwritten (0-9)\n",
    "# its available in sklearn datasets \n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', as_frame = False, parser='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d913e",
   "metadata": {},
   "source": [
    "# 3. Data Glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df706ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee838e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y = mnist.data, mnist.target\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d723526c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543407de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', ..., '4', '5', '6'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda42cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d619c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digit(image_data):\n",
    "    image = image_data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = 'binary')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f417a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = X[0]\n",
    "plot_digit(some_digit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3fef9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]\n",
    "\n",
    "# above picture looks like 5, also its target is 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553d73b",
   "metadata": {},
   "source": [
    "# 4. Spliting Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b10a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929825d5",
   "metadata": {},
   "source": [
    "# 5 Training a Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19929858",
   "metadata": {},
   "source": [
    "- objective \n",
    "  - though there are 10 class for classification\n",
    "  - we will start with basic, classifying only 2 classes either its five or non five\n",
    "  - binary classifier\n",
    "  \n",
    "**Stochastic Gradient**\n",
    "  - Classifier is capable of handling very large datasets,\n",
    "  - SGD Can escape local minima more easily due to its stochastic nature.\n",
    "  - suited for online learning,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ba4435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.035\n"
     ]
    }
   ],
   "source": [
    "y_train_5 = (y_train == '5') # true for all 5s, False for all other digits\n",
    "y_test_5 = (y_test == '5')\n",
    "\n",
    "\n",
    "print(y_train_5.sum()/len(y_train_5)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab872f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# initialize the classifier ------\n",
    "sgd_clf = SGDClassifier(random_state = 42)\n",
    "\n",
    "# fit the model -------------\n",
    "\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344a5795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the data\n",
    "\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575899f",
   "metadata": {},
   "source": [
    "# 6. Performance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a6254",
   "metadata": {},
   "source": [
    "## 6.1 Measuring Accuracy using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcabc1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measuring Accuracy using Cross validation\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score = cross_val_score(estimator = sgd_clf, X = X_train, y=y_train_5, cv = 3, scoring = 'accuracy') \n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above we have recieved more than 95% accuracy in all 3 sets. is it correct\n",
    "# lets validate with dummy classifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier()\n",
    "\n",
    "dummy_clf.fit(X_train, y_train_5)\n",
    "\n",
    "print(any(dummy_clf.predict(X_train))) # here print \"false\" means no 5's detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34752e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check cross validation score tooo\n",
    "\n",
    "cross_val_score(estimator = dummy_clf, X = X_train, y = y_train_5, cv = 3, scoring = 'accuracy')\n",
    "\n",
    "#Here also all 3 sets, accuracy score is greater than 90%\n",
    "\n",
    "# this states that \"accuracy \" is generally not preferred performance measure for classifiers, especially when you are dealing skewed datasets (when some classes are more frequent than others)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d667e42e",
   "metadata": {},
   "source": [
    "- Here also all 3 sets, accuracy score is greater than 90%\n",
    "\n",
    "- this states that **\"accuracy\" is generally not preferred performance measure for classifiers**, especially when you are dealing **skewed datasets** (when some classes are more frequent than others)\n",
    "- **Confusiion Matrix** CM, is considered a much better metric to evaluate the performance of a classifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb1ce6",
   "metadata": {},
   "source": [
    "# implementing Cross validation own\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits = 3) # add shuffle = true if dataset is not already suffled\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_fold = X_train[train_index]\n",
    "    y_train_fold = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    \n",
    "    print(n_correct/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f4f39d",
   "metadata": {},
   "source": [
    "## 6.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999f18a",
   "metadata": {},
   "source": [
    "- **cross_val_predict is a powerful tool for obtaining cross-validated predictions that can enhance your model evaluation process**. \n",
    "- It’s particularly useful when you want to get a clearer picture of how your model performs across the entire dataset while using cross-validation techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross val preditct\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(estimator = sgd_clf, X = X_train, y= y_train_5, cv =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd796ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets create confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train_5, y_train_pred) #(actual , and predicated)\n",
    "\n",
    "\n",
    "cm \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc90c9",
   "metadata": {},
   "source": [
    "**each row represents actual class**, \n",
    "**while each column represnts predicated class**\n",
    "   - first row considers non_five images ,\n",
    "        - out of which 53892 are predicated non_five images (true Negatives), \n",
    "        - while 687 were wrongly classified as five images (**type 1 error, false positives**)\n",
    "   - second row considers five's images\n",
    "        - 1891 were wrongly mapped non_five images (**type 2 error, false Negative**)\n",
    "        - 3530 wre correctly mapped as five's images (true Positives)\n",
    "        \n",
    "- A perfect classifier should have only true positives and true negatives "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a30016d",
   "metadata": {},
   "source": [
    "**Precision and Recall**\n",
    "\n",
    "- Precision  = TP/(TP+FP)\n",
    "- Recall = TP/(TP+FN) , also known as **sensitivity  or true positive rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# via sklearn\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "print('precision', precision_score(y_train_5, y_train_pred))\n",
    "print('recall', recall_score(y_train_5, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a0f337",
   "metadata": {},
   "source": [
    "from above Numbers\n",
    "  - when it claims an image represnts a 5's, it is correct only 83%\n",
    "  - moreover its detect only 65% of 5's\n",
    "  \n",
    "  \n",
    "---\n",
    "### -----------------------\n",
    "---\n",
    "\n",
    "- its always convient to combine precision and recall into a single metric, called **F1 score**, \n",
    "- **single metric is helpful to compare two classifiers**\n",
    "- F1_score is harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0d709a",
   "metadata": {},
   "source": [
    "**Why Harmonic mean not arithmetic mean**\n",
    "\n",
    "- Both scores are important\n",
    "\n",
    "- **The harmonic mean used in the F1 score provides a more conservative estimate that emphasizes the lower of the two metrics (precision and recall), making it a better choice for scenarios where both metrics are important**.\n",
    "\n",
    "- Example\n",
    "    - Precision =0.9\n",
    "    - recall = 0.1\n",
    "    \n",
    "    then \n",
    "    - arithmetic mean = (a+b)/2 = (0.9 + 0.1) = 0.5\n",
    "    - harmonic mean = 2ab/(a+b) = (2 * 0.9 * 0.1)/(0.9 + 0.1) = 0.18\n",
    "    \n",
    "- **The F1 score provides a more balanced measure of a model's performance, especially in situations where there is an imbalance between the classes**. \n",
    "  - This is particularly relevant in scenarios where false negatives (missed positive instances) are more critical than false positives (incorrect positive predictions) or vice versa.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f601285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccec577",
   "metadata": {},
   "source": [
    "## 6.3 Precision and Recall Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be0fdac",
   "metadata": {},
   "source": [
    "**F1 scores favors classifiers that have similar precision and recall**\n",
    "  - But this is not always we want\n",
    "  - sometimes Precision is more important \n",
    "  - sometimes Recall is more important\n",
    "  \n",
    "**When Precision is more Important**\n",
    "\n",
    "  - **Defination** : Precision is the ratio of true positive predictions to the total predicted positives (true positives + false positives). High precision indicates a low false positive rate.\n",
    "\n",
    "  - **Priortization** When False Positives are Costly: In situations where falsely identifying a positive instance leads to significant negative consequences, you should prioritize precision.\n",
    "\n",
    "  - **Example** \n",
    "  \n",
    "      - **Email Spam Detection** when its legitamte email, it will lead to missing critical information\n",
    "      - **Using facial recognition to grant access to secure areas**\n",
    "\n",
    "\n",
    "\n",
    "**When Recall is more Important**\n",
    "\n",
    "  - **Priortization** When False Negatives are Costly: In scenarios where failing to identify a positive instance has severe consequences, recall should be prioritized.\n",
    " \n",
    " - Example \n",
    "      - **Video classifying safe for kids**\n",
    "      - **Screening tests for a serious disease like cancer**\n",
    "      - **Locating missing persons or disaster victims**\n",
    "        \n",
    "**Precision and recall are intertwined**; increasing precision reduces recall and vice versa. This is known as the **precision-recall trade-off**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25d40b",
   "metadata": {},
   "source": [
    "- scikit learn   classifier had a function which gives **'decision_function()'** method which returns a score for each instance and then we can set a threhsold  to make predication,  \n",
    "\n",
    "\n",
    "- Enabling you to navigate the precision-recall trade-off effectively. This flexibility is particularly valuable in scenarios where the costs of false positives and false negatives differ significantly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3442b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(some_digit)\n",
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "print(y_scores)\n",
    "\n",
    "# the deafult threshold for sgd_classifier is zero\n",
    "\n",
    "threshold = 0\n",
    "\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "print(y_some_digit_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets raise the threshold\n",
    "\n",
    "threshold = 3000\n",
    "\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "print(y_some_digit_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e0b0e",
   "metadata": {},
   "source": [
    "This confirms that raising the threshold decreases recall. The image actually represents a 5, and the classifier detects it when the threshold is 0, but it misses it when the threshold is increased to 3,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to decide which threshold to use\n",
    "## lets cv_predict but this time with decision_scores method\n",
    "\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv = 3, method = 'decision_function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, precisions[:-1], \"b--\", label = \"Precision\", linewidth = 2)\n",
    "plt.plot(thresholds, recalls[:-1], \"g-\", label = \"Recall\", linewidth = 2)\n",
    "plt.vlines(thresholds, 0,1, \"k\", 'dotted', label = \"threshold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e695ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting precision and recall against thresholds\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "\n",
    "# Vertical lines at threshold values\n",
    "plt.vlines(thresholds, 0, 1, colors='k', linestyles='dotted', label=\"Threshold\")\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Precision/Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce122b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5/6, 4/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recalls, precisions, linewidth = 2 , label = 'Precision/Recall Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ea7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacab5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_for_90_precision = (precisions >= 0.90).argmax()\n",
    "print([idx_for_90_precision])\n",
    "\n",
    "threshold_for_90_precision = thresholds[idx_for_90_precision]\n",
    "\n",
    "print(threshold_for_90_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208fbf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make predications based on threshold_90, (insted of calling classifier predict predict() method)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "y_train_pred_90 = (y_scores >= threshold_for_90_precision)\n",
    "\n",
    "unique,counts = np.unique(y_train_pred_90, return_counts = True)\n",
    "\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf836cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check precision and recall for these predications\n",
    "\n",
    "\n",
    "print(precision_score(y_train_5, y_train_pred_90))\n",
    "\n",
    "recall_at_90_precison = recall_score(y_train_5, y_train_pred_90)\n",
    "\n",
    "print(recall_at_90_precison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b092fef8",
   "metadata": {},
   "source": [
    "**using these techinque we can calcualte any precision we want**\n",
    "  - just set enough threshold`\n",
    "  - though above recall value is not great, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0b59a",
   "metadata": {},
   "source": [
    "## 6.4 ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433af129",
   "metadata": {},
   "source": [
    "- ROC: Receiver Operating Characterstics curve\n",
    "- another common tool used with **binary classifications**\n",
    "- similar to Precision and recall curve but instead of plotting Precision-Recall curve, \n",
    "\n",
    "- **It plots the true positive rate (TPR/Recall) against the false positive rate (FPR/ Fall out) at various classification thresholds**.\n",
    "- FPR is the ratio Negative instances that are incorrectly classified as positive.\n",
    "- FPR is equal to (1- true Negative Rate) \n",
    "- TNR is also specificity\n",
    "- ROC curve plot Sensitivty(Recall) vs \"1 - Specificity\"\n",
    "- TPR VS FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac4f03",
   "metadata": {},
   "source": [
    "| | Predicted Negative | Predicted Positive |\n",
    "|---|---|---|\n",
    "| Actual Negative | TN | FP |\n",
    "| Actual Positive | FN | TP |\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "* **AUC:** A higher AUC indicates better overall performance.\n",
    "* **ROC Curve:** A curve closer to the top-left corner indicates better sensitivity and specificity.\n",
    "* **Threshold:** The optimal threshold can be determined by considering the desired balance between sensitivity and specificity based on the specific application.\n",
    "\n",
    "\n",
    "- **Sensitivity**: True Positive Rate (TPR) = TP / (TP + FN)\n",
    "- **Fall out**: False Positive Rate (FPR) = FP/(FP+TN)\n",
    "\n",
    "### -- -- -- -- --\n",
    "- **Specificity**: True Negative Rate (TNR) = TN / (TN + FP)\n",
    "- **Precision**: TP / (TP + FP)\n",
    "- **Recall**: **TPR**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e84c1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14072bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot roc curve , we have to use roc_curve() function to get TPR and FPR\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96894414",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([fpr, tpr, thresholds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the point that corresponds to 90% precision, we need to look for the index of the desired threshold\n",
    "\n",
    "idx_for_threshold_at_90 = (thresholds <= threshold_for_90_precision).argmax()\n",
    "\n",
    "tpr_90, fpr_90 = tpr[idx_for_threshold_at_90],fpr[idx_for_threshold_at_90]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, linewidth = 2, label = 'ROC curve')\n",
    "\n",
    "plt.plot([0,1],[   0,1],linestyle = ':', color = 'red', label = \"Random classifier's ROC curve\")\n",
    "\n",
    "plt.plot([fpr_90], [tpr_90], 'ko', label = \"Threshold for 90% precision\")\n",
    "\n",
    "\n",
    "# Adding a title and labels\n",
    "plt.title('ROC Curve Example')\n",
    "plt.xlabel('False Positive Rate (Recall)')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "# Display the legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ee88c",
   "metadata": {},
   "source": [
    "- the dotted line represents the ROC curve of a purely random classifier\n",
    "- a good classifier stays as far  away from that line as possible\n",
    "\n",
    "- **one way to classify the ROC curve is to measure the area under the curve(AUC)**\n",
    "- a perfect classifier will have roc_aoc equal to 1\n",
    "- a purely random classifier will have a roc_aoc equal to 0.5\n",
    "- scikit learn provides function to estimate the roc_auc value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cf9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "roc_auc_score(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf65c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c66d265c",
   "metadata": {},
   "source": [
    "### Since ROC curve is similar to precision recall curve, when to use which one?\n",
    "\n",
    "- We should prefer the PR curve whenver the positive class is rare or we care more about the false positives than false negatives\n",
    "- Otherwise ROC curve\n",
    "- here, MNIST digit representation, that too 5's or not 5's, 5's are rare (only 10% of data, PR curve makes sense here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9eff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a random classifier and compare with sgdclassifier results\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv = 3, method = 'predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eefcb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas_forest[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b10df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(10):\n",
    "    plot_digit(X[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the second column represnts the estimated probabilites for the positive class \n",
    "\n",
    "y_scores_forest = y_probas_forest[:,1]\n",
    "print(y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c7aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions_forest, recalls_forest, thresholds_forest = precision_recall_curve(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recalls_forest, precisions_forest, \"b-\", linewidth = 2,label = \"RandomForest\")\n",
    "\n",
    "\n",
    "plt.plot(recalls, precisions, \"r--\", linewidth = 2, label = \"SGD\")\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel ('ylabel')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99dc761",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_forest = y_probas_forest[:,1]>= 0.5 # positive proba\n",
    "\n",
    "print(f1_score(y_train_5, y_train_pred_forest))\n",
    "print(roc_auc_score(y_train_5, y_scores_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5111db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sgd f1 score\", f1_score(y_train_5, y_train_pred))\n",
    "print('sgd roc_auc_score', roc_auc_score(y_train_5, y_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a4ee8",
   "metadata": {},
   "source": [
    "- RandomForestClassifier’s PR curve looks much better than the SGDClassifier’s: \n",
    "- it comes much closer to the top-right corner. \n",
    "- Its F1 score and ROC AUC score are also significantly better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349984c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d4fcc64",
   "metadata": {},
   "source": [
    "# 7. Multimodel Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff0df5",
   "metadata": {},
   "source": [
    "- Binary classifiers: Classify two classes\n",
    "- Multiclass classifiers : Classify multiple classes\n",
    "\n",
    "- **Some scikit learn classifier is capable of handling multiple classes**\n",
    "   - Logistic Regression\n",
    "   - Random Forest\n",
    "   - GaussianNB\n",
    "- Others are **strictly binary classifiers**\n",
    "   - SGD Classifier\n",
    "   - SVC\n",
    "- However they are various ways, we can use to perform multiclass classification with multiple binary classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeee11f",
   "metadata": {},
   "source": [
    "#### Multiple classification using multiple binary classification\n",
    "\n",
    "\n",
    "  - **OVR: One versus Rest also know as OVA (one Versus All)** strategy\n",
    "      - for mnist data, to classify the digit images into 10 classes (0 to 9) is to train **10 bianry classifiers**\n",
    "           - selecting the class whose classifier outputs the highest score.\n",
    "           \n",
    "  - **OVO: One versus One** Strategy\n",
    "       - here we have to train a binary classifer for every pair of digits,\n",
    "           - 0 vs 1, 0 vs 2, .... 1 vs 2 , 1 vs 3 , ... 8 vs 9\n",
    "           - if there is N classes, we need to train `N*(N-1))/2` classifiers. for Mnist  we have to train 45 classifiers\n",
    "           - The OvO strategy’s main advantage is that each classifier is trained only on the data related to the two classes it is trying to distinguish, which allows for more efficient learning, faster training times, and potentially improved classification accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78117e1",
   "metadata": {},
   "source": [
    "| Criteria                       | Use OvR                                   | Use OvO                                   |\n",
    "|--------------------------------|-------------------------------------------|-------------------------------------------|\n",
    "| Number of Classes              | Large classes (many)                      | Small classes (few)                       |\n",
    "| Class Imbalance                 | Better for imbalanced datasets            | Can handle imbalance but less directly    |\n",
    "| Computational Efficiency        | More efficient (fewer classifiers)       | Less efficient (more classifiers)         |\n",
    "| Model Complexity                | Simple models (e.g., logistic regression) | Complex models (e.g., SVMs)               |\n",
    "| Interpretability                | Easier to interpret                       | Can be more complex to interpret          |\n",
    "| Specific Nuances in Classes     | Less detail per classifier                | More detail per pair of classes           |\n",
    "| Overall Accuracy                | Good for simpler decision boundaries      | Potentially higher accuracy with complex boundaries |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d7f096",
   "metadata": {},
   "source": [
    "- some algorithms (SVM classifiers)  scale pooorly with size of training set\n",
    "- For these type of algo's OvO is preferred, becasues its faster to train many classifiers  on small training data sets than to train few classifiers on large training sets\n",
    "- for most classifications algorithms **OvR** is preferred\n",
    "\n",
    "\n",
    "# ------\n",
    "\n",
    "- SKlearn, detects automatically when to use binary classification for a multiclass classification task. **and it automatically runs Ovr or Ovr** depending on algorithm\n",
    "\n",
    "- lets try with only 2k observation with SVC algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5bde38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(random_state = 42)\n",
    "svm_clf.fit(X_train[:2000], y_train[:2000])\n",
    "\n",
    "#  Scikit-Learn used the OvO strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810324d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit_scores = svm_clf.decision_function([some_digit])\n",
    "some_digit_scores.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efde83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = some_digit_scores.argmax()\n",
    "class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to force scikit learn to use one versus one or one versus rest\n",
    "   #OneVsOneClassifier\n",
    "   #OneVsRestClassifier\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "ovr_svm_clf = OneVsRestClassifier(SVC(random_state = 42))\n",
    "ovr_svm_clf.fit(X_train[:2000], y_train[:2000])\n",
    "\n",
    "ovr_svm_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ovr_svm_clf.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54229280",
   "metadata": {},
   "source": [
    "#### Training SGD Classifier on multiclass dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e67d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state = 42)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c2d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above is predication error , this time scikit learn used OvR strategy under the hood\n",
    "# since there are 10 classes, it train 10 binary classification\n",
    "# lets chech values using decision function method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72088b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.decision_function([some_digit]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from above output, we can see that 3 is the best with 1823 score, while all are negative, second best is 5( which is true)\n",
    "# lets check cross val score too\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train, cv = 3, scoring = 'accuracy')\n",
    "\n",
    "# in all the sets, we we get around 86% accuracy, not a bad score\n",
    "\n",
    "# we can insrease the accuracy using scaling the inputs` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype('float64'))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv = 3, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f0d555",
   "metadata": {},
   "source": [
    "# 8 Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdeefc",
   "metadata": {},
   "source": [
    "#### in real project, we need to do extra more work , like \n",
    "  - data exploration\n",
    "  - try out multiple models\n",
    "  - shortlist best model\n",
    "  - fine tune their hyperparameters using GridSearchCV\n",
    "  - automate as much as possible\n",
    "\n",
    "\n",
    "**But for now, assume we found the best model and we want to find ways to imporve it futher** \n",
    "   - one ways to analyze the types of errors it makes\n",
    "   - First, look at the confusion matrix\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1c5f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can notice in above fig, row 5 and col 5, is more darker than other main diagonal elemnts\n",
    "# this may be happening because of wrong predications of 5 or \n",
    "# lesser number of 5's data, which we have to normalize by each classification image with total number of images\n",
    "# this normalize can be done easily on \"ConfusionMatrixDisplay\" by setting normalize = 'true'\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, normalize = \"true\", values_format = \".0%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of the erros had happened misclassifying 8, alot of differnt numbers mapped as 8\n",
    "\n",
    "# if you want to visulaize the error more, \n",
    "  # - we have to put zero weights the correct classifications \n",
    "\n",
    "    \n",
    "sample_weight = (y_train_pred != y_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, \n",
    "                                        sample_weight = sample_weight,\n",
    "                                       normalize = 'true', values_format = '.0%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb70e72a",
   "metadata": {},
   "source": [
    "- analyzing individuals errors can be also be good way to gain insights\n",
    "\n",
    "- Data augmentation: Approach consists of augmenting the training data set with slightly shifted and rotated variants of the training images. This will force the model to learn  to be more tolerant to such variations.\n",
    "\n",
    "\n",
    "- Data augmentation is a technique commonly used in machine learning, especially in computer vision, to increase the size and diversity of a training dataset by creating modified versions of existing data. This is particularly useful when you have limited data and want to improve the performance and generalization of your model. The key idea is to apply transformations to the data in a way that preserves the underlying information while introducing variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d4e7c9",
   "metadata": {},
   "source": [
    "# 9. Multilabel Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743e4dd",
   "metadata": {},
   "source": [
    "- until now, each instance has always been assigned to just one class\n",
    "- But in some cases you may want your classifier to output multiple classes for each instance\n",
    "- example \n",
    "     - Face-Recognition classifier \n",
    "          - classifier has been trained to classify a picture among three faces Gadkari, Rahul, Kejriwal\n",
    "          - suppose a picture is shown where Gadkari and Kejriwal present, then it will give output [True, False, True]\n",
    "     - Movie type tagging : Comedy, Horror, Drama , Scifi, Adventure\n",
    "            - Stree : comedy, horror\n",
    "     \n",
    "     - this type of classification system gives outputs multiple binary tags\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb517dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "y_train_large = (y_train >= '7')\n",
    "y_train_odd = (y_train.astype('int8')%2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88010baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.predict([some_digit])\n",
    "\n",
    "# yes its right, the digit is indeed not large [False], and odd [true]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02dd9c4",
   "metadata": {},
   "source": [
    "## 9.2 Evalute a Multilabel classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808840f5",
   "metadata": {},
   "source": [
    "- there are many ways to evalute a multilabel classifier and selecting right metric\n",
    "- it really depends on the project\n",
    "\n",
    "\n",
    "- one Approcach is to measure the F1 socre for each individual lable, then simply compute the average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c882c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2067cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_multilabel, y_train_knn_pred, average = 'macro')\n",
    "\n",
    "# this approach assumes that all labels are equally important, which may not be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa439ba1",
   "metadata": {},
   "source": [
    "- if we have many more pictues of Gadkari than Rahul and kejriwal, \n",
    "- we need to give more weight to the classifier's score on picture of Gadkari\n",
    "- one simple option is to give each label a weight equal to its support (i.e. the the number of instances with that target lable)\n",
    "- it can be done by setting average = 'weighted' when calling F1_score function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ddea0",
   "metadata": {},
   "source": [
    "- some of the classifier doesn't support Multilable Classification, eg SVC\n",
    "- one possible strategy is to train one model per label\n",
    "\n",
    "- these types models can be trained in a chain method. \n",
    "   - when a model makes a predications, it uses the input features plus all the predications of the models that come before it in the chain\n",
    "    \n",
    "\n",
    "-scikit learn has a class called ChainClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc8dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import ClassifierChain\n",
    "\n",
    "chain_clf = ClassifierChain(SVC(), cv = 3, random_state = 42)\n",
    "chain_clf.fit(X_train[:2000], y_multilabel[:2000])\n",
    "\n",
    "\n",
    "chain_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf69af",
   "metadata": {},
   "source": [
    "# 10. Multiouput Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022745ef",
   "metadata": {},
   "source": [
    "- Multioutput Multiclass classification : generalization of multilabel classification where each label can be multiclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) \n",
    "\n",
    "noise = np.random.randint(0,100, (len(X_train), 784))\n",
    "X_train_mod = X_train + noise\n",
    "\n",
    "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
    "X_test_mod = X_test + noise\n",
    "\n",
    "y_train_mod = X_train\n",
    "y_test_mod = X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "\n",
    "clean_digit = knn_clf.predict([X_test_mod[0]])\n",
    "\n",
    "plot_digit(clean_digit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38f66b",
   "metadata": {},
   "source": [
    "## Happy Learning\n",
    "#### Science is the Systematic Classification of Experiences "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
