{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89ce1a6",
   "metadata": {},
   "source": [
    "**Batch Learning** and **Online Learning** are two approaches to training machine learning models, each suited to different types of problems and data availability.\n",
    "\n",
    "### **Batch Learning (Offline Learning)**\n",
    "In **batch learning**, the model is trained on the entire dataset at once. The training happens periodically or once when a large batch of data is collected.\n",
    "\n",
    "- **Process**: The model sees all the training data at once, computes the necessary adjustments, and creates a final model. If new data becomes available later, the model has to be retrained on the complete dataset, including both the old and new data.\n",
    "- **Example**: Training a neural network on a static dataset for image classification.\n",
    "\n",
    "#### **Pros of Batch Learning**:\n",
    "- **Efficiency**: For static datasets, it is computationally efficient and fast since it leverages the entire dataset at once.\n",
    "- **Accuracy**: Since the model is exposed to all data, it can often produce more accurate results.\n",
    "- **Optimal for Fixed Data**: It works well when the entire dataset is available and doesn’t change frequently.\n",
    "\n",
    "#### **Cons of Batch Learning**:\n",
    "- **Resource Intensive**: Requires significant memory and computational resources, especially for large datasets.\n",
    "- **Inflexible**: If new data becomes available, the entire training process must be repeated, which can be expensive and time-consuming.\n",
    "- **Not Ideal for Streaming Data**: It's impractical when the data is constantly updated or available in streams.\n",
    "\n",
    "---\n",
    "\n",
    "### **Online Learning**\n",
    "In **online learning**, the model is trained incrementally as new data arrives. It updates the model with each new data point or mini-batch rather than retraining it from scratch.\n",
    "\n",
    "- **Process**: Data arrives in a sequential manner, and the model updates itself continuously using that incoming data. This is often used in situations where data is too large to fit in memory or when data is constantly being updated (e.g., stock prices, real-time user behavior tracking).\n",
    "- **Example**: Training a recommendation system on user interactions as they happen in real time.\n",
    "\n",
    "#### **Pros of Online Learning**:\n",
    "- **Memory Efficient**: Only processes data as it comes, so it doesn't need to load the entire dataset into memory.\n",
    "- **Adaptability**: The model can adapt to changes in the data, making it ideal for real-time data streams or environments with dynamic data.\n",
    "- **Immediate Learning**: Updates are made as soon as new data arrives, which is useful in applications like fraud detection or stock price prediction.\n",
    "\n",
    "#### **Cons of Online Learning**:\n",
    "- **Risk of Overfitting**: If the model isn't carefully regularized, it may overfit to the most recent data or noisy data points.\n",
    "- **Complexity in Setup**: Requires careful design to ensure that updates are efficient and that the model doesn’t degrade over time (e.g., learning rate tuning, deciding when to stop updating).\n",
    "- **Potential Instability**: Sudden changes in the data distribution (e.g., concept drift) can lead to unstable performance unless properly managed.\n",
    "\n",
    "---\n",
    "\n",
    "### **Things to Look Out for in Both Cases**\n",
    "\n",
    "#### **Batch Learning Considerations**:\n",
    "1. **Data Size**: Ensure that the data is small enough to be handled in memory or that resources are available for large-scale distributed training.\n",
    "2. **Model Retraining Frequency**: Decide on a schedule for retraining the model if the data changes (daily, weekly, etc.).\n",
    "3. **Overfitting**: Watch for overfitting, especially when using complex models on small datasets.\n",
    "4. **Computation Time**: Training may take time, especially for large models and datasets.\n",
    "\n",
    "#### **Online Learning Considerations**:\n",
    "1. **Learning Rate**: Carefully choose the learning rate, as the model will be updated frequently. A high rate can lead to forgetting important older patterns; a low rate may slow learning.\n",
    "2. **Data Order**: Data order can influence model performance. Ensure that data isn't biased towards certain time periods or categories.\n",
    "3. **Concept Drift**: Continuously monitor model performance to detect shifts in the underlying data patterns.\n",
    "4. **Memory and Resource Management**: Ensure that the system can efficiently handle real-time data without running out of memory or processing power.\n",
    "\n",
    "Both approaches have their strengths and trade-offs, and the choice between them depends on factors like the nature of the data, computational resources, and application needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dd776d",
   "metadata": {},
   "source": [
    "# 2 Plotting Excercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe8b4f",
   "metadata": {},
   "source": [
    "- histogram\n",
    "- boxplot\n",
    "- stacked chart\n",
    "- cluster chart\n",
    "- scatter plot\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013687c",
   "metadata": {},
   "source": [
    "Here are some **common plotting techniques** that every data scientist should know, with examples of when and why they are useful:\n",
    "\n",
    "### 1. **Histogram**\n",
    "   - **Use Case**: To understand the distribution of a single continuous variable.\n",
    "   - **Description**: A histogram groups data into bins and shows how frequently each bin occurs.\n",
    "   - **Example**: Visualizing the distribution of house prices, customer ages, or income levels.\n",
    "   - **Key Insight**: Helps identify the shape of the data distribution (e.g., normal, skewed, bimodal).\n",
    "\n",
    "   ```python\n",
    "   import matplotlib.pyplot as plt\n",
    "   plt.hist(data['price'], bins=20)\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### 2. **Boxplot (Box-and-Whisker Plot)**\n",
    "   - **Use Case**: To visualize the distribution, spread, and outliers of continuous data.\n",
    "   - **Description**: Displays the minimum, first quartile (Q1), median (Q2), third quartile (Q3), and maximum values. Outliers are also marked.\n",
    "   - **Example**: Comparing salary distributions between different departments or age distributions by gender.\n",
    "   - **Key Insight**: Highlights central tendency and the presence of outliers.\n",
    "\n",
    "   ```python\n",
    "   import seaborn as sns\n",
    "   sns.boxplot(x='department', y='salary', data=df)\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### 3. **Stacked Chart**\n",
    "   - **Use Case**: To compare multiple categories over time or another continuous variable.\n",
    "   - **Description**: A stacked chart combines several bar plots or area charts into a single chart, showing the contribution of each category to the total.\n",
    "   - **Example**: Showing the breakdown of expenses by category (e.g., marketing, salaries, operations) over time.\n",
    "   - **Key Insight**: Visualizes how individual parts contribute to a whole over a continuous range.\n",
    "\n",
    "   ```python\n",
    "   df.groupby(['year', 'category']).size().unstack().plot(kind='bar', stacked=True)\n",
    "   ```\n",
    "\n",
    "### 4. **Cluster Chart**\n",
    "   - **Use Case**: To display groups or clusters in a dataset.\n",
    "   - **Description**: A cluster chart uses color or shapes to represent different clusters (or groups) of data points.\n",
    "   - **Example**: Visualizing K-means clustering results on customer segmentation data.\n",
    "   - **Key Insight**: Helps identify patterns of similarity within groups and differences between groups.\n",
    "\n",
    "   ```python\n",
    "   from sklearn.cluster import KMeans\n",
    "   plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_)\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### 5. **Scatter Plot**\n",
    "   - **Use Case**: To visualize relationships between two continuous variables.\n",
    "   - **Description**: Each point represents a data observation, and its position is defined by two variables, one on the x-axis and one on the y-axis.\n",
    "   - **Example**: Visualizing the relationship between advertising spend and revenue.\n",
    "   - **Key Insight**: Useful for identifying correlations, clusters, or patterns such as trends.\n",
    "\n",
    "   ```python\n",
    "   plt.scatter(df['ad_spend'], df['revenue'])\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### 6. **Line Chart**\n",
    "   - **Use Case**: To track changes over time or sequential data.\n",
    "   - **Description**: A line chart connects individual data points with lines. It’s typically used when the x-axis represents time or a continuous variable.\n",
    "   - **Example**: Plotting stock prices or sales revenue over time.\n",
    "   - **Key Insight**: Great for showing trends and patterns over time.\n",
    "\n",
    "   ```python\n",
    "   plt.plot(df['date'], df['sales'])\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### 7. **Pair Plot (Scatterplot Matrix)**\n",
    "   - **Use Case**: To visualize pairwise relationships in a dataset.\n",
    "   - **Description**: Displays a matrix of scatter plots for all variable combinations in the dataset. It’s useful for exploring multivariate data.\n",
    "   - **Example**: Checking relationships between features like height, weight, and age in a health dataset.\n",
    "   - **Key Insight**: Quickly gives insights into the relationships between multiple variables.\n",
    "\n",
    "   ```python\n",
    "   sns.pairplot(df)\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### 8. **Heatmap**\n",
    "   - **Use Case**: To visualize matrix data or correlations between variables.\n",
    "   - **Description**: A heatmap uses color gradients to represent data values in a grid format.\n",
    "   - **Example**: Visualizing the correlation matrix between features in a dataset.\n",
    "   - **Key Insight**: Makes it easy to spot correlations, trends, or patterns.\n",
    "\n",
    "   ```python\n",
    "   sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### 9. **Violin Plot**\n",
    "   - **Use Case**: To show the distribution of data across different categories, combining the benefits of boxplots and density plots.\n",
    "   - **Description**: Displays the distribution of a dataset across several categories.\n",
    "   - **Example**: Comparing distributions of exam scores across multiple schools.\n",
    "   - **Key Insight**: Provides insight into both distribution shape and summary statistics.\n",
    "\n",
    "   ```python\n",
    "   sns.violinplot(x='school', y='exam_score', data=df)\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### 10. **Bar Plot**\n",
    "   - **Use Case**: To compare categorical data.\n",
    "   - **Description**: A bar plot displays categorical data with rectangular bars representing the count or value of each category.\n",
    "   - **Example**: Visualizing sales across different regions or product categories.\n",
    "   - **Key Insight**: Simple, clear comparison of categorical data.\n",
    "\n",
    "   ```python\n",
    "   sns.barplot(x='region', y='sales', data=df)\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "### 11. **Bubble Plot**\n",
    "   - **Use Case**: To display three dimensions of data in a 2D scatter plot.\n",
    "   - **Description**: A scatter plot where the size of the dots represents a third variable.\n",
    "   - **Example**: Comparing GDP, population size, and life expectancy of countries.\n",
    "   - **Key Insight**: Good for visualizing multiple variables simultaneously.\n",
    "\n",
    "   ```python\n",
    "   plt.scatter(df['GDP'], df['life_expectancy'], s=df['population']/1000)\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "Each of these plotting techniques is essential for exploring, understanding, and communicating insights from data. The choice of plot depends on the type of data and the story you want to tell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86bf304",
   "metadata": {},
   "source": [
    "I'll use the famous **Iris dataset** from Scikit-learn to create these visualizations. The Iris dataset contains measurements of 150 iris flowers from three species, with four features (sepal length, sepal width, petal length, and petal width).\n",
    "\n",
    "Here's a code example that uses this dataset and creates all the visualizations mentioned earlier.\n",
    "\n",
    "### Load the Dataset\n",
    "First, let's load the Iris dataset:\n",
    "\n",
    "```python\n",
    "# Load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['species'] = iris.target\n",
    "df['species'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "df.head()  # Display the first few rows\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Histogram**\n",
    "\n",
    "```python\n",
    "plt.hist(df['sepal length (cm)'], bins=10, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Sepal Length')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Boxplot (Box-and-Whisker Plot)**\n",
    "\n",
    "```python\n",
    "sns.boxplot(x='species', y='sepal length (cm)', data=df)\n",
    "plt.title('Boxplot of Sepal Length by Species')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Stacked Bar Chart**\n",
    "\n",
    "For this, I will group the species and count how many observations fall under each category of `sepal length`.\n",
    "\n",
    "```python\n",
    "stacked_data = df.groupby(['species']).size().unstack()\n",
    "stacked_data.plot(kind='bar', stacked=True, color=['blue', 'orange', 'green'])\n",
    "plt.title('Stacked Bar Chart of Species Counts')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Cluster Chart (Using KMeans Clustering)**\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Applying KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "df['cluster'] = kmeans.fit_predict(df.iloc[:, :-1])\n",
    "\n",
    "# Plotting clusters\n",
    "plt.scatter(df['sepal length (cm)'], df['sepal width (cm)'], c=df['cluster'], cmap='viridis')\n",
    "plt.title('Cluster Plot (KMeans)')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Sepal Width (cm)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Scatter Plot**\n",
    "\n",
    "```python\n",
    "plt.scatter(df['sepal length (cm)'], df['petal length (cm)'], c=df['species'].map({'setosa': 0, 'versicolor': 1, 'virginica': 2}), cmap='coolwarm')\n",
    "plt.title('Scatter Plot of Sepal vs Petal Length')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Petal Length (cm)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Line Chart**\n",
    "\n",
    "```python\n",
    "df.groupby('species')['sepal length (cm)'].mean().plot(kind='line', marker='o', color='green')\n",
    "plt.title('Average Sepal Length by Species')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Average Sepal Length (cm)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Pair Plot (Scatterplot Matrix)**\n",
    "\n",
    "```python\n",
    "sns.pairplot(df, hue='species')\n",
    "plt.title('Pairplot of Iris Features by Species')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Heatmap**\n",
    "\n",
    "```python\n",
    "corr = df.iloc[:, :-2].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Heatmap of Feature Correlations')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Violin Plot**\n",
    "\n",
    "```python\n",
    "sns.violinplot(x='species', y='petal length (cm)', data=df)\n",
    "plt.title('Violin Plot of Petal Length by Species')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 10. **Bar Plot**\n",
    "\n",
    "```python\n",
    "sns.barplot(x='species', y='sepal width (cm)', data=df)\n",
    "plt.title('Bar Plot of Sepal Width by Species')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 11. **Bubble Plot**\n",
    "\n",
    "```python\n",
    "plt.scatter(df['sepal length (cm)'], df['petal width (cm)'], s=df['sepal width (cm)'] * 100, c=df['species'].map({'setosa': 0, 'versicolor': 1, 'virginica': 2}), alpha=0.5, cmap='viridis')\n",
    "plt.title('Bubble Plot: Sepal Length vs Petal Width')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Petal Width (cm)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "This covers all the visualization types listed! Each plot offers different insights into the Iris dataset, helping with both data exploration and presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d23f9e",
   "metadata": {},
   "source": [
    "# -- -- -- -- --\n",
    "\n",
    "Sure! Let's imagine K-Nearest Neighbors (KNN) in a **3D space**—this will help visualize how the algorithm works in a more intuitive way.\n",
    "\n",
    "### Picture the 3D world:\n",
    "\n",
    "- You have data points floating in a **3D space** with three axes: **X**, **Y**, and **Z** (imagine these axes represent three features or variables of your data).\n",
    "- Each point in this space represents a **data instance** with values for these three features.\n",
    "- In the case of **KNN classification**, each point belongs to a **class**. Let’s say you have two classes: \"Red\" points and \"Blue\" points, like floating colored spheres in space.\n",
    "\n",
    "### How KNN works in this 3D world:\n",
    "\n",
    "1. **New Point Introduction**:\n",
    "   - Imagine you're given a **new point**, say a green-colored sphere, and your job is to classify whether it belongs to the \"Red\" class or the \"Blue\" class.\n",
    "   \n",
    "2. **Looking for Neighbors**:\n",
    "   - To classify the new point, KNN looks for its **`k` nearest neighbors** in the 3D space.\n",
    "   - You can picture this as drawing an **imaginary sphere around the green point** and expanding its radius until it includes `k` nearest neighbors (say 5). These neighbors will be other spheres (data points) from the Red or Blue classes.\n",
    "\n",
    "3. **Distance in 3D**:\n",
    "   - To determine how \"close\" a point is in 3D space, KNN uses a **distance metric**, most commonly the **Euclidean distance**. In simple terms, Euclidean distance in 3D is the shortest straight-line distance between two points in space.\n",
    "   \n",
    "   - Mathematically, the distance between two points \\( (x_1, y_1, z_1) \\) and \\( (x_2, y_2, z_2) \\) is:\n",
    "   \n",
    "     \\[\n",
    "     d = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}\n",
    "     \\]\n",
    "   \n",
    "   - In our example, the algorithm calculates the distances from the green point to all the other points in the dataset to find the closest neighbors.\n",
    "\n",
    "4. **Voting (For Classification)**:\n",
    "   - Once the nearest neighbors are identified, KNN performs **voting**: it counts how many of these neighbors belong to the \"Red\" class and how many belong to the \"Blue\" class.\n",
    "   - If a majority of the neighbors are Red, the green point will be classified as Red; if more are Blue, then it will be classified as Blue.\n",
    "\n",
    "5. **For Regression**:\n",
    "   - In regression tasks, instead of voting for a class, KNN takes the **average** of the target values from the nearest neighbors to predict the value for the new point.\n",
    "\n",
    "### What Happens as You Change `k`:\n",
    "\n",
    "- **Small `k`** (e.g., `k = 1`): \n",
    "  - The green point's class is assigned based on just its closest neighbor. This can lead to **overfitting**, where the classification is too sensitive to local variations (e.g., noise).\n",
    "  \n",
    "- **Larger `k`** (e.g., `k = 5` or `k = 10`):\n",
    "  - KNN looks at more neighbors, which can provide a **smoother** classification, reducing the impact of any one noisy data point. However, too large of a `k` could make the classification too **generalized**, losing fine detail.\n",
    "\n",
    "### Example to Picture:\n",
    "\n",
    "- Imagine you drop a new green point into a floating 3D cloud of Red and Blue points.\n",
    "- KNN grows a sphere around the green point until it has found, say, 5 nearest neighbors.\n",
    "- Based on whether the majority of these 5 neighbors are Red or Blue, KNN classifies the green point as one of the two classes.\n",
    "\n",
    "### 3D World Summary:\n",
    "- In this 3D world, KNN is like a person in the middle of the crowd trying to decide what \"group\" (Red or Blue) to join based on who is closest to them.\n",
    "- The **distance** metric in this 3D world helps decide who the closest people (data points) are, and the decision (classification) is made by seeing the most frequent group (majority voting).\n",
    "\n",
    "This visualization can help you imagine KNN as a geometric, distance-based algorithm that uses the position and proximity of points to make predictions or classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57339c7e",
   "metadata": {},
   "source": [
    "# -- -- -- -- --\n",
    "**Here’s the comparison between K-Nearest Neighbors (KNN) and K-Means in Markdown format**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d91185",
   "metadata": {},
   "source": [
    "| Feature                       | K-Nearest Neighbors (KNN)                          | K-Means                                      |\n",
    "|-------------------------------|--------------------------------------------------|----------------------------------------------|\n",
    "| **Type**                      | Supervised learning                               | Unsupervised learning                        |\n",
    "| **Purpose**                   | Classification (or regression)                   | Clustering                                   |\n",
    "| **Data Input**                | Requires labeled data (target variable needed)   | Works with unlabeled data                    |\n",
    "| **Output**                    | Class labels (or continuous values)              | Cluster centroids and group assignments      |\n",
    "| **How it Works**              | Finds `k` nearest neighbors in training data to make predictions | Partitions data into `k` clusters based on distance to centroids |\n",
    "| **Distance Metric**           | Typically uses Euclidean distance (can vary)    | Usually uses Euclidean distance to determine cluster membership |\n",
    "| **Model Training**            | No explicit training phase; instance-based       | Initializes centroids and iteratively updates them based on data |\n",
    "| **Complexity**                | Computationally expensive for large datasets (as it calculates distances for each prediction) | Generally more efficient once clusters are formed |\n",
    "| **Hyperparameter**            | `k` (number of neighbors)                         | `k` (number of clusters)                     |\n",
    "| **Scalability**               | Less scalable; performance decreases with large datasets | More scalable, especially with optimized implementations |\n",
    "| **Interpretability**          | Easy to interpret since it directly uses the training data for predictions | Can be less intuitive; requires understanding of cluster centers |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab9320",
   "metadata": {},
   "source": [
    "**While K-Means itself is not suitable for categorical data, adaptations and alternative algorithms can be employed to achieve similar clustering objectives**. \n",
    "  - If you have a dataset with categorical variables, \n",
    "    - consider using **K-Modes or K-Prototypes**, or appropriately encoding the data before applying K-Means.\n",
    "       - K-Modes: An extension of K-Means specifically designed for categorical data. Instead of means, K-Modes uses modes (most frequent categories) to find the centroid of clusters and uses a dissimilarity measure suited for categorical data.\n",
    "       - K-Prototypes: Combines K-Means and K-Modes to handle datasets with both categorical and numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4cd2f",
   "metadata": {},
   "source": [
    "## -- -- -- -- --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ebe4b9",
   "metadata": {},
   "source": [
    "Sure! Let’s go through a simple example of K-Modes clustering using hand calculations. \n",
    "\n",
    "### Example Dataset\n",
    "Consider a small dataset with three categorical features representing different attributes of three items:\n",
    "\n",
    "| Item | Color | Shape   | Size   |\n",
    "|------|-------|---------|--------|\n",
    "| 1    | Red   | Circle  | Small  |\n",
    "| 2    | Blue  | Square  | Medium |\n",
    "| 3    | Red   | Square  | Medium |\n",
    "| 4    | Blue  | Circle  | Large  |\n",
    "| 5    | Red   | Circle  | Medium |\n",
    "\n",
    "### Step 1: Choose `k`\n",
    "Let’s choose **`k = 2`** (we want to form 2 clusters).\n",
    "\n",
    "### Step 2: Initialize Centroids\n",
    "We can randomly select two items as initial centroids. Let’s say we choose:\n",
    "\n",
    "- Centroid 1: Item 1 (Red, Circle, Small)\n",
    "- Centroid 2: Item 2 (Blue, Square, Medium)\n",
    "\n",
    "### Step 3: Assign Items to Nearest Centroid\n",
    "To assign each item to the nearest centroid, we will calculate the dissimilarity (using the **mode** for categorical attributes). The dissimilarity measure for K-Modes is calculated based on the number of differing features.\n",
    "\n",
    "#### Dissimilarity Calculation\n",
    "\n",
    "| Item | Color | Shape   | Size   | Centroid 1 | Centroid 2 | Nearest Centroid |\n",
    "|------|-------|---------|--------|-------------|-------------|-------------------|\n",
    "| 1    | Red   | Circle  | Small  | 0           | 3           | Centroid 1       |\n",
    "| 2    | Blue  | Square  | Medium | 3           | 0           | Centroid 2       |\n",
    "| 3    | Red   | Square  | Medium | 2           | 2           | Centroid 1       |\n",
    "| 4    | Blue  | Circle  | Large  | 3           | 2           | Centroid 2       |\n",
    "| 5    | Red   | Circle  | Medium | 1           | 2           | Centroid 1       |\n",
    "\n",
    "- **Dissimilarity to Centroid 1 (Red, Circle, Small)**:\n",
    "  - Item 1: 0 (same)\n",
    "  - Item 2: 3 (different)\n",
    "  - Item 3: 2 (2 attributes differ: Shape, Size)\n",
    "  - Item 4: 3 (different)\n",
    "  - Item 5: 1 (1 attribute differs: Size)\n",
    "\n",
    "- **Dissimilarity to Centroid 2 (Blue, Square, Medium)**:\n",
    "  - Item 1: 3 (different)\n",
    "  - Item 2: 0 (same)\n",
    "  - Item 3: 2 (2 attributes differ: Color, Shape)\n",
    "  - Item 4: 2 (1 attribute differs: Shape)\n",
    "  - Item 5: 2 (1 attribute differs: Color)\n",
    "\n",
    "### Step 4: Update Cluster Assignments\n",
    "Based on the nearest centroid, we assign items to clusters:\n",
    "\n",
    "- **Cluster 1 (Centroid 1)**: Items 1, 3, 5\n",
    "- **Cluster 2 (Centroid 2)**: Items 2, 4\n",
    "\n",
    "### Step 5: Update Centroids\n",
    "Next, we calculate the new centroids based on the mode of the attributes in each cluster.\n",
    "\n",
    "#### New Centroid for Cluster 1:\n",
    "- Color: **Red** (mode: Red, occurs 3 times)\n",
    "- Shape: **Circle** (mode: Circle, occurs 2 times)\n",
    "- Size: **Medium** (mode: Medium, occurs 2 times)\n",
    "\n",
    "So, the new centroid for Cluster 1 is (Red, Circle, Medium).\n",
    "\n",
    "#### New Centroid for Cluster 2:\n",
    "- Color: **Blue** (mode: Blue, occurs 2 times)\n",
    "- Shape: **Circle** (mode: Circle, occurs 1 time)\n",
    "- Size: **Medium** (mode: Medium, occurs 2 times)\n",
    "\n",
    "So, the new centroid for Cluster 2 is (Blue, Circle, Medium).\n",
    "\n",
    "### Step 6: Repeat Steps 3-5\n",
    "Now, we repeat the assignment and update steps with the new centroids.\n",
    "\n",
    "#### Dissimilarity with New Centroids\n",
    "\n",
    "| Item | Color | Shape   | Size   | Centroid 1 (Red, Circle, Medium) | Centroid 2 (Blue, Circle, Medium) | Nearest Centroid |\n",
    "|------|-------|---------|--------|-----------------------------------|------------------------------------|-------------------|\n",
    "| 1    | Red   | Circle  | Small  | 1                                 | 3                                  | Centroid 1       |\n",
    "| 2    | Blue  | Square  | Medium | 3                                 | 0                                  | Centroid 2       |\n",
    "| 3    | Red   | Square  | Medium | 2                                 | 2                                  | Centroid 1       |\n",
    "| 4    | Blue  | Circle  | Large  | 2                                 | 2                                  | Centroid 2       |\n",
    "| 5    | Red   | Circle  | Medium | 0                                 | 2                                  | Centroid 1       |\n",
    "\n",
    "- Assign items based on the nearest centroid again:\n",
    "\n",
    "- **Cluster 1 (Centroid 1)**: Items 1, 3, 5\n",
    "- **Cluster 2 (Centroid 2)**: Items 2, 4\n",
    "\n",
    "### Conclusion\n",
    "The clusters have stabilized after one iteration of updating the centroids, with each item assigned to its nearest cluster based on categorical attributes. K-Modes efficiently groups similar items based on mode calculations, making it suitable for clustering categorical data. \n",
    "\n",
    "### Final Clusters:\n",
    "- **Cluster 1**: Items 1 (Red, Circle, Small), 3 (Red, Square, Medium), 5 (Red, Circle, Medium)\n",
    "- **Cluster 2**: Items 2 (Blue, Square, Medium), 4 (Blue, Circle, Large)\n",
    "\n",
    "This hand-calculation example shows how K-Modes can cluster categorical data by using modes to determine centroids and the dissimilarity measure to assign items to clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677086d0",
   "metadata": {},
   "source": [
    "Gower’s Distance\n",
    "Definition: Gower's distance is a metric used to measure dissimilarity between two objects, accommodating mixed data types (both categorical and continuous). It normalizes the contribution of different types of variables, making it suitable for datasets with both types of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882bac4d",
   "metadata": {},
   "source": [
    "# -- -- -- -- --\n",
    "# what is ROC Curve , what does it represent\n",
    "\n",
    "Sure! The **Receiver Operating Characteristic (ROC) curve** is a graphical representation used to evaluate the performance of a binary classification model. It helps to understand the trade-off between sensitivity (true positive rate) and specificity (false positive rate) at various threshold settings.\n",
    "\n",
    "\n",
    "| Predicted | Negative (Bad) | Positive (Good) |\n",
    "|---|---|---|\n",
    "| Actual: Bad | TN | FP |\n",
    "| Actual: Good | FN | TP |\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **True Positive Rate (TPR)**: Also known as **sensitivity or recall**, it is the proportion of actual positives that are correctly identified by the model.\n",
    "   $$\n",
    "   \\text{TPR} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\n",
    "   $$\n",
    "\n",
    "2. **False Positive Rate (FPR)**: This measures the proportion of actual negatives that are incorrectly identified as positives.\n",
    "   $$\n",
    "   \\text{FPR} = \\frac{\\text{False Positives (FP)}}{\\text{False Positives (FP)} + \\text{True Negatives (TN)}}\n",
    "   $$\n",
    "\n",
    "3. **Threshold**: The probability threshold at which the predicted probabilities are converted into class labels. By adjusting this threshold, we can observe how the TPR and FPR change.\n",
    "\n",
    "### Creating an ROC Curve\n",
    "\n",
    "1. **Calculate TPR and FPR**: For different threshold values ranging from 0 to 1, calculate the TPR and FPR.\n",
    "2. **Plot the ROC Curve**: The ROC curve is plotted with the FPR on the x-axis and TPR on the y-axis.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Diagonal Line (Chance Level)**: A diagonal line from (0, 0) to (1, 1) represents the performance of a random classifier (no discrimination). If the ROC curve lies close to this line, it indicates poor performance.\n",
    "  \n",
    "- **Area Under the Curve (AUC)**: The AUC is a single value that summarizes the performance of the model. \n",
    "  - **AUC = 0.5**: Indicates no discrimination (model is no better than random guessing).\n",
    "  - **AUC = 1**: Indicates perfect discrimination (model perfectly classifies all positives and negatives).\n",
    "  - **AUC > 0.7**: Generally considered acceptable performance; higher values indicate better performance.\n",
    "\n",
    "### Example\n",
    "\n",
    "Imagine you have a binary classification model predicting whether an email is spam (positive) or not spam (negative). By calculating TPR and FPR at various thresholds based on the predicted probabilities of spam, you might generate the following ROC curve:\n",
    "\n",
    "- At a low threshold (e.g., 0.1), most emails are classified as spam, resulting in a high TPR but also a high FPR.\n",
    "- As you increase the threshold, you get a better FPR, but the TPR decreases.\n",
    "  \n",
    "The curve visualizes this trade-off, allowing you to choose the threshold that balances sensitivity and specificity according to your needs.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- The ROC curve is a valuable tool for assessing the diagnostic ability of a binary classifier.\n",
    "- It provides insights into the trade-offs between true positive and false positive rates, helping in threshold selection.\n",
    "- The AUC gives a quantitative measure of the model’s overall performance, aiding comparisons across different models.\n",
    "\n",
    "### Visualization\n",
    "\n",
    "Here's a general way to visualize an ROC curve:\n",
    "\n",
    "```plaintext\n",
    "       TPR\n",
    "        |\n",
    "        |             *\n",
    "        |          *\n",
    "        |        *\n",
    "        |     *\n",
    "        |   *\n",
    "        | *\n",
    "        |_________________________________ FPR\n",
    "        0          1\n",
    "```\n",
    "\n",
    "In this visualization, the curve rises sharply before leveling off, indicating a good balance between TPR and FPR across different thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8555e3a",
   "metadata": {},
   "source": [
    "- **Specificity=1−FPR**\n",
    "\n",
    "   - specificity =  TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3170b0ce",
   "metadata": {},
   "source": [
    "# -- -- -- -- --\n",
    "The **ROC curve** and the **AUC-ROC curve** are related concepts, but they refer to different aspects of model evaluation in binary classification.\n",
    "\n",
    "### ROC Curve\n",
    "\n",
    "- **Definition**: The **Receiver Operating Characteristic (ROC) curve** is a graphical representation that illustrates the performance of a binary classification model at various threshold settings.\n",
    "- **Axes**: \n",
    "  - **X-axis**: False Positive Rate (FPR)\n",
    "  - **Y-axis**: True Positive Rate (TPR) or Recall\n",
    "- **Purpose**: The ROC curve helps visualize the trade-off between sensitivity (TPR) and specificity (1 - FPR) as the classification threshold varies.\n",
    "- **Interpretation**: A curve closer to the top-left corner of the plot indicates better model performance, as it represents a higher TPR with a lower FPR.\n",
    "\n",
    "### AUC-ROC\n",
    "\n",
    "- **Definition**: **Area Under the ROC Curve (AUC-ROC)** quantifies the overall performance of the model across all classification thresholds by calculating the area under the ROC curve.\n",
    "- **Value Range**: \n",
    "  - AUC values range from 0 to 1.\n",
    "  - **AUC = 0.5**: Indicates no discrimination (model performs no better than random guessing).\n",
    "  - **AUC = 1**: Indicates perfect discrimination (model perfectly classifies all positives and negatives).\n",
    "  - **AUC > 0.7**: Generally considered acceptable performance; higher values indicate better performance.\n",
    "- **Purpose**: AUC provides a single metric that summarizes the model’s ability to distinguish between the positive and negative classes, making it easier to compare different models.\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Concept          | Definition                                             | Purpose                                   |\n",
    "|------------------|-------------------------------------------------------|-------------------------------------------|\n",
    "| **ROC Curve**    | A plot that illustrates TPR vs. FPR at various thresholds | Visualizes the trade-off between sensitivity and specificity |\n",
    "| **AUC-ROC**      | A single value representing the area under the ROC curve | Quantifies overall model performance across all thresholds |\n",
    "\n",
    "### Example Scenario\n",
    "\n",
    "1. **ROC Curve**: Suppose you have a binary classifier for spam detection. By calculating TPR and FPR at various thresholds (e.g., 0.1, 0.2, ... , 0.9), you can plot the ROC curve to visualize how well the classifier separates spam from non-spam emails.\n",
    "\n",
    "2. **AUC-ROC**: After plotting the ROC curve, you calculate the area under the curve (AUC) to summarize the classifier's performance. If the AUC is 0.85, it indicates that the model has a good ability to distinguish between spam and non-spam.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "In summary, while the **ROC curve** provides a visual representation of model performance across different thresholds, **AUC-ROC** quantifies that performance into a single number, allowing for easier comparisons between different models. If you have further questions or need additional clarification, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ecfed",
   "metadata": {},
   "source": [
    "## --- --- --- ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6f07c",
   "metadata": {},
   "source": [
    "You're right that there are numerous metrics to evaluate the performance of regression and classification models, each with its strengths and weaknesses. Choosing the right metrics depends on the context of your problem and the specific goals of your analysis. Below is a breakdown of common metrics for both regression and classification, along with guidance on when to use them.\n",
    "\n",
    "### Regression Metrics\n",
    "\n",
    "1. **Mean Absolute Error (MAE)**:\n",
    "   - **Definition**: Average absolute difference between predicted and actual values.\n",
    "   - **Use When**: You want a straightforward interpretation of errors without penalizing larger errors more than smaller ones.\n",
    "\n",
    "2. **Mean Squared Error (MSE)**:\n",
    "   - **Definition**: Average squared difference between predicted and actual values.\n",
    "   - **Use When**: You want to penalize larger errors more significantly. It is sensitive to outliers.\n",
    "\n",
    "3. **Root Mean Squared Error (RMSE)**:\n",
    "   - **Definition**: Square root of the MSE, providing error in the same units as the target variable.\n",
    "   - **Use When**: You want an interpretable measure of model performance, especially when comparing models.\n",
    "\n",
    "4. **R-squared (R²)**:\n",
    "   - **Definition**: Proportion of variance in the target variable that can be explained by the independent variables.\n",
    "   - **Use When**: You want to understand the goodness of fit of your model. Values range from 0 to 1, where higher values indicate better fit.\n",
    "\n",
    "5. **Adjusted R-squared**:\n",
    "   - **Definition**: R-squared adjusted for the number of predictors in the model.\n",
    "   - **Use When**: You want to account for model complexity and prevent overfitting, especially when comparing models with different numbers of predictors.\n",
    "\n",
    "6. **Mean Absolute Percentage Error (MAPE)**:\n",
    "   - **Definition**: Average absolute percentage difference between predicted and actual values.\n",
    "   - **Use When**: You want a measure that is scale-independent and easily interpretable as a percentage.\n",
    "\n",
    "### Classification Metrics\n",
    "\n",
    "1. **Accuracy**:\n",
    "   - **Definition**: Proportion of correctly classified instances over total instances.\n",
    "   - **Use When**: Classes are balanced. Not reliable for imbalanced datasets.\n",
    "\n",
    "2. **Precision**:\n",
    "   - **Definition**: Proportion of true positive predictions over total positive predictions.\n",
    "   - **Use When**: You want to minimize false positives (e.g., in spam detection).\n",
    "\n",
    "3. **Recall (Sensitivity)**:\n",
    "   - **Definition**: Proportion of true positive predictions over actual positives.\n",
    "   - **Use When**: You want to minimize false negatives (e.g., in disease detection).\n",
    "\n",
    "4. **F1 Score**:\n",
    "   - **Definition**: Harmonic mean of precision and recall, balancing both metrics.\n",
    "   - **Use When**: You want a balance between precision and recall, especially in imbalanced datasets.\n",
    "   \n",
    "   - $F_\\beta$ score\n",
    "      - $$F_\\beta = (1 + β²) * (precision * recall) / (β² * precision + recall)$$\n",
    "        - β is a parameter that controls the relative importance of precision and recall.\n",
    "        - β = 2 for F2-score (more emphasis on precision)\n",
    "        - β = 1 for F1-score (equal emphasis on precision and recall)\n",
    "        - β = 0.5 for F0.5-score (more emphasis on recall)\n",
    "\n",
    "5. **Weighted F1 Score**:\n",
    "   - **Definition**: F1 score calculated for each class, weighted by the number of instances in each class.\n",
    "   - **Use When**: You want to account for class imbalance in multi-class problems.\n",
    "\n",
    "6. **AUC-ROC**:\n",
    "   - **Definition**: Area under the ROC curve, representing the model's ability to distinguish between classes.\n",
    "   - **Use When**: You want an aggregate measure of performance across all classification thresholds.\n",
    "\n",
    "7. **Binary Cross-Entropy**:\n",
    "   - **Definition**: A loss function that quantifies the difference between the predicted probabilities and actual binary labels.\n",
    "   - **Use When**: You are working with probabilistic models and want to optimize them based on likelihood.\n",
    "\n",
    "8. **Log Loss**:\n",
    "   - **Definition**: Similar to binary cross-entropy, quantifying the performance of a classification model where the prediction is a probability value between 0 and 1.\n",
    "   - **Use When**: You want to evaluate the accuracy of probability predictions.\n",
    "\n",
    "### Choosing the Right Metrics\n",
    "\n",
    "1. **Context Matters**: The choice of metric depends on the problem context. For instance, in medical diagnoses, you might prioritize recall to minimize false negatives.\n",
    "\n",
    "2. **Consider Class Balance**: Use accuracy in balanced datasets; for imbalanced datasets, prefer precision, recall, or F1 score.\n",
    "\n",
    "3. **Model Evaluation Sequence**:\n",
    "   - **Start with Basic Metrics**: Accuracy, MAE, or RMSE for initial evaluation.\n",
    "   - **Use Robust Metrics**: Precision, recall, F1 score for detailed insights in classification; R², Adjusted R² for regression.\n",
    "   - **Evaluate Thresholds**: Use ROC/AUC for binary classification to determine optimal thresholds.\n",
    "   - **Cross-Validation**: Consider k-fold cross-validation to validate model performance across multiple folds.\n",
    "\n",
    "### Additional Metrics to Consider\n",
    "\n",
    "#### Regression\n",
    "\n",
    "- **Coefficient of Variation**: Ratio of the standard deviation to the mean, useful for comparing variability.\n",
    "- **Max Error**: Maximum error between predicted and actual values, useful for understanding worst-case scenarios.\n",
    "\n",
    "#### Classification\n",
    "\n",
    "- **Confusion Matrix**: A table that shows true vs. predicted values, providing a comprehensive view of model performance.\n",
    "- **Cohen's Kappa**: Measures the agreement between predicted and actual classifications, considering chance agreement.\n",
    "- **Matthews Correlation Coefficient (MCC)**: A balanced measure for binary classification that accounts for true and false positives and negatives.\n",
    "\n",
    "### Summary\n",
    "\n",
    "In summary, the choice of metrics should align with your specific objectives and the characteristics of your dataset. It often helps to use multiple metrics to gain a comprehensive view of model performance. If you need further clarification or have specific scenarios in mind, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9001d7",
   "metadata": {},
   "source": [
    "**R-squared (R²)** is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. It provides insights into how well the model fits the data. Here’s how you can calculate R².\n",
    "\n",
    "### Calculation of R-squared (R²)\n",
    "\n",
    "1. **Definitions**:\n",
    "   - **Total Sum of Squares (SST)**: This measures the total variance in the dependent variable.\n",
    "   - **Residual Sum of Squares (SSR)**: This measures the variance that is not explained by the model.\n",
    "   - **Explained Sum of Squares (SSE)**: This measures the variance explained by the model.\n",
    "\n",
    "2. **Formulas**:\n",
    "   - **SST**: $\\text{SST} = \\sum (y_i - \\bar{y})^2$\n",
    "     \n",
    "     Where $y_i$ is the actual value and $\\bar{y}$ is the mean of the actual values.\n",
    "\n",
    "   - **SSR**:$\\text{SSR} = \\sum (y_i - \\hat{y}_i)^2$\n",
    "     \n",
    "     Where \\(\\hat{y}_i\\) is the predicted value from the regression model.\n",
    "\n",
    "   - **SSE**:\n",
    "     \\[\n",
    "     \\text{SSE} = \\sum (\\hat{y}_i - \\bar{y})^2\n",
    "     \\]\n",
    "\n",
    "3. **R-squared Calculation**:\n",
    "   $$R^2 = 1 - \\frac{\\text{SSR}}{\\text{SST}}$$\n",
    "Alternatively, it can also be expressed as:\n",
    "\\[\n",
    "R^2 = \\frac{\\text{SSE}}{\\text{SST}}\n",
    "\\]\n",
    "\n",
    "### Step-by-Step Example\n",
    "\n",
    "Let's say you have the following dataset:\n",
    "\n",
    "| Actual (y) | Predicted (\\(\\hat{y}\\)) |\n",
    "|------------|-------------------------|\n",
    "| 3          | 2.5                     |\n",
    "| 4          | 4.0                     |\n",
    "| 2          | 2.5                     |\n",
    "| 5          | 5.5                     |\n",
    "\n",
    "#### Step 1: Calculate the Mean of Actual Values\n",
    "\n",
    "\\[\n",
    "\\bar{y} = \\frac{3 + 4 + 2 + 5}{4} = 3.5\n",
    "\\]\n",
    "\n",
    "#### Step 2: Calculate SST\n",
    "\n",
    "\\[\n",
    "\\text{SST} = (3 - 3.5)^2 + (4 - 3.5)^2 + (2 - 3.5)^2 + (5 - 3.5)^2\n",
    "\\]\n",
    "\\[\n",
    "= (-0.5)^2 + (0.5)^2 + (-1.5)^2 + (1.5)^2\n",
    "\\]\n",
    "\\[\n",
    "= 0.25 + 0.25 + 2.25 + 2.25 = 5\n",
    "\\]\n",
    "\n",
    "#### Step 3: Calculate SSR\n",
    "\n",
    "\\[\n",
    "\\text{SSR} = (3 - 2.5)^2 + (4 - 4.0)^2 + (2 - 2.5)^2 + (5 - 5.5)^2\n",
    "\\]\n",
    "\\[\n",
    "= (0.5)^2 + (0)^2 + (-0.5)^2 + (-0.5)^2\n",
    "\\]\n",
    "\\[\n",
    "= 0.25 + 0 + 0.25 + 0.25 = 0.75\n",
    "\\]\n",
    "\n",
    "#### Step 4: Calculate R-squared\n",
    "\n",
    "Using the formula:\n",
    "\\[\n",
    "R^2 = 1 - \\frac{\\text{SSR}}{\\text{SST}} = 1 - \\frac{0.75}{5} = 1 - 0.15 = 0.85\n",
    "\\]\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- An R² value of **0.85** indicates that **85%** of the variance in the actual values can be explained by the model.\n",
    "- This suggests a strong fit of the regression model to the data.\n",
    "\n",
    "### Key Points\n",
    "\n",
    "- **R² values range from 0 to 1**: \n",
    "  - 0 indicates that the model explains none of the variability.\n",
    "  - 1 indicates that the model explains all the variability.\n",
    "- **Caveat**: R² alone does not determine whether the regression model is adequate. It is essential to consider other metrics and perform residual analysis for a complete evaluation of the model’s performance.\n",
    "\n",
    "If you have any further questions or need more examples, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c818d1f",
   "metadata": {},
   "source": [
    "## -- -- -- -- --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968ed5c",
   "metadata": {},
   "source": [
    "**Mean Absolute Percentage Error (MAPE)** is a measure of prediction accuracy in a forecasting method. It expresses the accuracy as a percentage, making it easy to interpret. MAPE is particularly useful because it is scale-independent, allowing for comparison across different datasets or models.\n",
    "\n",
    "MAPE Formula\n",
    "The formula for calculating MAPE is:\n",
    "    $$MAPE = 100 * ∑(|Ai - Fi| / Ai) / n$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd7b96",
   "metadata": {},
   "source": [
    "## -- -- -- --\n",
    "\n",
    "When evaluating regression models, both R-squared (R²) and Root Mean Squared Error (RMSE) are useful metrics, but they serve different purposes and provide different insights into the model's performance\n",
    "\n",
    "- **Use R² when you're interested in how well the model explains the variance of the dependent variable and for model comparison**.\n",
    "- **Use RMSE when you're focused on the accuracy of predictions and want to understand how much error to expect in real-world applications**.\n",
    "\n",
    "Which to Prioritize?\n",
    "\n",
    "- in regression analysis, the main focus can vary depending on the specific goals of the modeling effort, but generally, it revolves around **two key aspects: explaining the variance and reducing the magnitude of prediction error**.\n",
    "\n",
    "  - **Exploratory Analysis**: If your primary goal is to understand relationships within the data and identify key predictors, then focusing on the proportion of variance explained (using metrics like R²) is essential.\n",
    "\n",
    "  - **Prediction Accuracy**: If your main objective is to develop a model that makes accurate predictions on new data, then reducing the magnitude of prediction error (using metrics like RMSE, MAE, etc.) is more important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59bf235",
   "metadata": {},
   "source": [
    "### -- -- -- -- --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3e5c64",
   "metadata": {},
   "source": [
    "**Collinearity and Multicollinearity**\n",
    "-  Both are related concepts in regression analysis that refer to relationships between independent variables (predictors)\n",
    "-  **Collinearity**: It occurs when two predictor variables in a regression model are highly correlated with each other.\n",
    "   - **Impact**: When two variables are collinear, it becomes difficult for the model to determine the individual effect of each predictor because they are providing redundant information.\n",
    "-  **Multicollinearity**: It is an extension of collinearity, where more than two predictor variables are highly correlated with each other.\n",
    "   - **Impact**: It leads to the same problems as collinearity but on a larger scale. Multicollinearity can inflate the variance of the coefficient estimates, making them sensitive to minor changes in the model.\n",
    "   \n",
    "| Aspect      | Collinearity                           | Multicollinearity                                  |\n",
    "|-------------|----------------------------------------|---------------------------------------------------|\n",
    "| **Scope**   | Relationship between two variables     | Involves more than two variables                   |\n",
    "| **Definition** | Two predictors are highly correlated  | A set of predictors is highly intercorrelated      |\n",
    "| **Impact**  | Affects the interpretation of two variables | Affects the stability and interpretation of all variables |\n",
    "| **Detection** | Pairwise correlation (e.g., Pearson correlation) | Variance Inflation Factor (VIF), Eigenvalue analysis |\n",
    "| **Severity** | A specific case of correlation between two variables | More generalized, involving multiple predictors    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007adf0",
   "metadata": {},
   "source": [
    "### Does Collinearity and multicollinearity can affect classification models\n",
    "\n",
    "- **Yes, collinearity and multicollinearity can affect classification models, especially those that estimate coefficients i.e linear models (like logistic regression or linear SVM)**.\n",
    "- Tree-based methods (like Random Forests) and non-linear SVMs are less sensitive to multicollinearity, but feature importance interpretation might still be influenced.\n",
    "- It’s important to detect and potentially address multicollinearity if you rely on interpretable models, particularly in logistic regression.\n",
    "\n",
    "- To address these issues, you can:\n",
    "  - Feature Engineering: Combine or transform features to reduce correlation.\n",
    "  - Feature Selection: Remove redundant features.\n",
    "  - Regularization Techniques: Use techniques like L1 or L2 regularization to penalize large coefficients and reduce the impact of correlated features.\n",
    "  - Principal Component Analysis (PCA): Transform the data into a new set of uncorrelated features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a2adbe",
   "metadata": {},
   "source": [
    "### --- --- --- --- ---\n",
    "\n",
    "**Eigenvalues and Eigenvectors: A Brief Overview**\n",
    "- Eigenvalues and eigenvectors are fundamental concepts in linear algebra that have significant applications in various fields, including machine learning.\n",
    "\n",
    "- **Eigenvector**: A non-zero vector that remains unchanged in direction when multiplied by a square matrix.\n",
    "- **Eigenvalue**: A scalar value associated with an eigenvector that represents the factor by which the eigenvector is scaled when multiplied by the matrix.\n",
    "\n",
    "                   $$Av = \\lambda v$$ \n",
    "    - v is matrix, A is a square matrix, $\\lambda$ is a value\n",
    "    - if above equation forms, then **v is a eigenvector of A matrix**\n",
    "\n",
    "- **In essence, an eigenvector is a special vector that the matrix can \"stretch\" or \"shrink\" without changing its direction, and the eigenvalue is the factor by which it is stretched or shrunk**.\n",
    "\n",
    "- https://www.youtube.com/watch?v=9CT0jnem4vM\n",
    "\n",
    "- for two by two matrix , there will be two eigen vector and two eigen value\n",
    "- and similarly for 3 by 3 matrix, there will be 3 eigen vector and 3 eigen values\n",
    "\n",
    "**Main Purpose in Machine Learning**\n",
    "In machine learning, eigenvalues and eigenvectors are primarily used in:\n",
    "\n",
    " - Principal Component Analysis (PCA): PCA is a dimensionality reduction technique that identifies the most important features (principal components) in a dataset. Eigenvectors represent the principal components, and their corresponding eigenvalues indicate the variance explained by each component.   \n",
    " - Singular Value Decomposition (SVD): SVD is a matrix factorization technique that decomposes a matrix into three smaller matrices. Eigenvalues and eigenvectors play a crucial role in SVD, as the singular values and singular vectors are related to the eigenvalues and eigenvectors of the matrix's Gramian matrix.\n",
    "- Eigenvalue Analysis of Matrices: Analyzing the eigenvalues of a matrix can provide insights into its properties, such as its stability, invertibility, and positive definiteness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821b73e",
   "metadata": {},
   "source": [
    "# -- -- -- -- -- --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b1862",
   "metadata": {},
   "source": [
    "No, the **Gini Index** and **Information Gain** are not the same, although they serve similar purposes in decision tree algorithms for determining the best feature to split on.\n",
    "\n",
    "### Gini Index:\n",
    "- **Used in**: Classification tasks, primarily in the **CART (Classification and Regression Trees)** algorithm.\n",
    "- **Measures**: The impurity or \"mixing\" of classes in a dataset.\n",
    "- **Formula**: \\( Gini = 1 - \\sum_{i=1}^{n} p_i^2 \\), where \\( p_i \\) is the probability of a class.\n",
    "  - If all elements in a node belong to the same class, Gini index is 0 (pure).\n",
    "  - If there's a mix of classes, the Gini index increases towards 1.\n",
    "\n",
    "### Information Gain (IG):\n",
    "- **Used in**: Both **ID3, C4.5, and C5.0** algorithms.\n",
    "- **Measures**: The reduction in entropy after a dataset is split on an attribute.\n",
    "- **Formula**: \\( IG = Entropy(parent) - \\sum (\\frac{|child|}{|parent|} \\times Entropy(child)) \\)\n",
    "  - **Entropy** quantifies uncertainty in the dataset. High entropy means more uncertainty.\n",
    "  - Information Gain selects the feature that reduces this uncertainty the most.\n",
    "\n",
    "### Differences:\n",
    "- **Gini Index** focuses on class purity, while **Information Gain** focuses on reducing entropy (uncertainty).\n",
    "- Information Gain is based on **logarithmic calculations**, while Gini Index uses **squared probabilities**.\n",
    "- The two metrics might result in different splits for the same dataset, though often they lead to similar trees.\n",
    "\n",
    "Do you plan to use them in a specific project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b922e0",
   "metadata": {},
   "source": [
    "## -- -- -- -- --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556264f",
   "metadata": {},
   "source": [
    "No, **Information Gain** and **Entropy** are not the same, although they are closely related in the context of decision trees.\n",
    "\n",
    "### 1. **Entropy**:\n",
    "- **Measures**: The level of **uncertainty** or **impurity** in a dataset. It quantifies how mixed the dataset is regarding the target classes.\n",
    "- **Formula**: \n",
    "  \\[\n",
    "  Entropy(S) = - \\sum_{i=1}^{n} p_i \\log_2 p_i\n",
    "  \\]\n",
    "  where \\(p_i\\) is the probability of class \\(i\\).\n",
    "- **Range**: \n",
    "  - **0**: If all examples are of one class (pure).\n",
    "  - **1**: If the dataset is equally divided between all possible classes (maximum impurity).\n",
    "  \n",
    "For example:\n",
    "- If all examples in a dataset belong to the same class, entropy is **0** (pure, no uncertainty).\n",
    "- If the classes are equally distributed (50/50), entropy is **1** (high uncertainty).\n",
    "\n",
    "### 2. **Information Gain (IG)**:\n",
    "- **Measures**: The **reduction in entropy** after the dataset is split based on a feature.\n",
    "- **Formula**: \n",
    "  \\[\n",
    "  IG = Entropy(parent) - \\sum_{i=1}^{k} \\frac{|S_i|}{|S|} Entropy(S_i)\n",
    "  \\]\n",
    "  where:\n",
    "  - \\(S\\) is the parent set,\n",
    "  - \\(S_i\\) are the child subsets after splitting,\n",
    "  - \\(\\frac{|S_i|}{|S|}\\) is the proportion of data points in each child subset.\n",
    "\n",
    "### Relationship:\n",
    "- **Entropy** measures the uncertainty in a dataset.\n",
    "- **Information Gain** measures how much the uncertainty (entropy) is reduced after splitting the dataset based on a specific feature.\n",
    "\n",
    "In a decision tree:\n",
    "- The algorithm first computes the **entropy** of the parent node.\n",
    "- Then, for each possible feature split, it calculates the **Information Gain** to see how much entropy would be reduced.\n",
    "- The feature with the highest Information Gain is selected for the split.\n",
    "\n",
    "### Example:\n",
    "If you're building a decision tree, you'll first compute **entropy** to understand the dataset's impurity, and then use **Information Gain** to determine which feature reduces this impurity the most.\n",
    "\n",
    "Does this clarify it for you, or do you want to dive into an example calculation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8ccf7",
   "metadata": {},
   "source": [
    "# -- -- -- -- --\n",
    "\n",
    "**In a decision tree, the number of splits depends on the algorithm being used**:\n",
    "\n",
    "### 1. **Binary Splits (Two Parts)**:\n",
    "- **CART (Classification and Regression Trees)** algorithm, which is commonly used in decision trees, **always splits the data into two parts (binary split)**.\n",
    "  - Even for categorical variables, CART will try to group them into two partitions to simplify the split.\n",
    "  - For numerical variables, CART will find a threshold value and split the data into values **less than** or **greater than or equal to** that threshold.\n",
    "\n",
    "### 2. **Multi-way Splits (More than Two Parts)**:\n",
    "- **ID3, C4.5, and C5.0** algorithms allow **multi-way splits** based on categorical variables.\n",
    "  - For categorical variables with \\( n \\) possible values, the tree can split the data into \\( n \\) branches.\n",
    "  - For numerical variables, these algorithms still perform **binary splits**, but they do allow splitting into multiple intervals if categorical variables are involved.\n",
    "  \n",
    "### Summary:\n",
    "- **CART**: Binary splits only.\n",
    "- **ID3, C4.5, C5.0**: Can have multi-way splits for categorical variables but binary for numerical ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2394f612",
   "metadata": {},
   "source": [
    "# -- -- --- ---\n",
    "\n",
    "| **Algorithm** | **Supports Classification?** | **Supports Regression?** | **Input Variables Supported** | **Splitting Criterion**                             |\n",
    "|---------------|------------------------------|--------------------------|-------------------------------|-----------------------------------------------------|\n",
    "| **CART**      | Yes                          | Yes                      | Categorical and Numerical      | Gini Index (Classification) or MSE (Regression)     |\n",
    "| **ID3**       | Yes                          | No                       | Only Categorical               | Information Gain                                    |\n",
    "| **C4.5**      | Yes                          | Yes                      | Categorical and Numerical      | Gain Ratio                                          |\n",
    "| **C5.0**      | Yes                          | No                       | Categorical and Numerical      | Information Gain or Gain Ratio                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88342445",
   "metadata": {},
   "source": [
    "# -- -- -- -- --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7264e2a",
   "metadata": {},
   "source": [
    "The **Gini impurity** is a measure used in decision trees to quantify how **mixed** the classes (or labels) are in a dataset or node. It calculates the probability that a randomly chosen element would be **incorrectly classified** if it were labeled according to the distribution of labels in that node.\n",
    "\n",
    "- in decision tree, gini impurity and gini index mean samething, \n",
    "\n",
    "### **Mathematical Definition**:\n",
    "The Gini impurity is defined as:\n",
    "$$\n",
    "\\text{Gini Impurity} = 1 - \\sum_{i=1}^{n} p_i^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( p_i \\) is the proportion of elements that belong to class \\( i \\) in the node.\n",
    "- \\( n \\) is the number of classes.\n",
    "\n",
    "### **In Simple Terms**:\n",
    "- **Low Gini Impurity**: If all items in a node belong to the same class (pure), the Gini impurity is **0** (no impurity).\n",
    "- **High Gini Impurity**: If the items are evenly distributed across all classes, the impurity is higher, approaching **1**.\n",
    "\n",
    "It's a way to measure how good or bad a split is in terms of separating the data into clean groups. The lower the Gini impurity, the better the split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e6f15e",
   "metadata": {},
   "source": [
    "# --- --- --- --- ---\n",
    "\n",
    "In machine learning, understanding the difference between **parameters** and **hyperparameters** is essential for model development and tuning. Here’s a breakdown of each term:\n",
    "\n",
    "### **Parameters**\n",
    "- **Definition**: Parameters are the internal variables of a model that are learned from the training data during the training process. They are adjusted by the learning algorithm to minimize the error of the model.\n",
    "- **Examples**: \n",
    "  - In a linear regression model, the coefficients (weights) of the input features are parameters.\n",
    "  - In neural networks, weights and biases associated with each neuron are parameters.\n",
    "- **Nature**: Parameters are usually optimized automatically by the learning algorithm using techniques like gradient descent.\n",
    "\n",
    "### **Hyperparameters**\n",
    "- **Definition**: Hyperparameters are the external configuration variables that are set before the training process begins. They control the learning process and the structure of the model but are not learned from the data.\n",
    "- **Examples**:\n",
    "  - The number of neighbors \\( k \\) in the k-Nearest Neighbors (k-NN) algorithm.\n",
    "  - The learning rate in gradient descent.\n",
    "  - The number of layers and nodes in a neural network.\n",
    "  - The regularization strength in models like Lasso or Ridge regression.\n",
    "- **Nature**: Hyperparameters need to be manually tuned or optimized, often using techniques such as grid search, random search, or Bayesian optimization.\n",
    "\n",
    "### **Key Differences**\n",
    "| Aspect           | Parameters                       | Hyperparameters                  |\n",
    "|------------------|----------------------------------|----------------------------------|\n",
    "| Definition        | Internal model variables learned from data | External settings configured before training |\n",
    "| Learning          | Automatically adjusted during training | Manually set and tuned           |\n",
    "| Examples          | Weights in linear regression     | Number of neighbors in k-NN, learning rate |\n",
    "| Optimization      | Optimized through training       | Typically optimized through techniques like grid search |\n",
    "\n",
    "### **Summary**\n",
    "- **Parameters** are learned from the data and directly influence the model’s predictions.\n",
    "- **Hyperparameters** are set before training and govern the training process or the model's architecture but are not directly learned from the data.\n",
    "\n",
    "Understanding these distinctions is crucial for effectively building and tuning machine learning models! If you have any further questions or need clarification, feel free to ask!`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8866592b",
   "metadata": {},
   "source": [
    "# -- -- -- -- -- --\n",
    "\n",
    "\n",
    "| **Aspect**                       | **Gini Impurity**                             | **Entropy**                                 |\n",
    "|----------------------------------|-----------------------------------------------|---------------------------------------------|\n",
    "| **Concept**                      | Measures probability of misclassification.    | Measures uncertainty or disorder (from information theory). |\n",
    "| **Formula**                      | $( 1 - \\sum p_i^2 )$                         | $( - \\sum p_i \\log_2(p_i) )$               |\n",
    "| **Range**                        | [0, 0.5] for binary classification            | [0, 1] for binary classification             |\n",
    "| **Interpretation of Higher Values** | Reflects higher likelihood of misclassification. | Reflects higher uncertainty in class distribution. |\n",
    "| **Interpretation of Lower Values**  | Indicates higher purity (more certain classification). | Indicates lower uncertainty (more certain class distribution). |\n",
    "| **Computational Complexity**     | Simpler and faster to compute.                | Slightly more complex (logarithms involved). |\n",
    "| **Usage**                        | Default in CART trees (e.g., Random Forests).| Used in ID3, C4.5 trees (e.g., Decision Trees in sklearn). |\n",
    "| **Interpretation of Higher Values** | Reflects higher likelihood of misclassification. | Reflects higher uncertainty in class distribution. |\n",
    "| **Minima Concept**               | Looks for local minima based on immediate class distribution. | Looks for global minima by maximizing information gain across the dataset. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86048a56",
   "metadata": {},
   "source": [
    "# --- --- ---- ----\n",
    "**Autocorrelation Function (ACF)**\n",
    "\n",
    "Autocorrelation is a statistical measure that describes the correlation between a variable and its lagged values. In simpler terms, it measures how much a variable's past values are related to its current or future values.\n",
    "\n",
    "Autocorrelation Function (ACF) is a plot of the autocorrelation coefficients at different lags.\n",
    "\n",
    "**Interpreting the ACF**\n",
    "\n",
    "- Positive autocorrelation: If the ACF is positive at a lag, it means that the value of the variable at the current time is positively correlated with its value at that lag. For example, if the ACF is positive at lag 1, it indicates that higher values at the current time are likely to be followed by higher values at the next time period.\n",
    "\n",
    "- Negative autocorrelation: If the ACF is negative at a lag, it means that the value of the variable at the current time is negatively correlated with its value at that lag. For example, if the ACF is negative at lag 1, it indicates that higher values at the current time are likely to be followed by lower values at the next time period.\n",
    "\n",
    "- No autocorrelation: If the ACF is close to zero at a lag, it means that the value of the variable at the current time is not correlated with its value at that lag.\n",
    "\n",
    "\n",
    "**Decay of the ACF**\n",
    "  - The decay rate of the ACF is an important characteristic. It indicates how quickly the correlation between a variable and its lagged values diminishes as the lag increases.\n",
    "\n",
    "  - Slow decay: If the ACF decays slowly, it means that the correlation between the variable and its lagged values persists for a long time. This is often indicative of a strong autocorrelation or persistence in the data.\n",
    "\n",
    "  - Fast decay: If the ACF decays quickly, it means that the correlation between the variable and its lagged values diminishes rapidly as the lag increases. This is often indicative of a weak autocorrelation or no autocorrelation in the data.\n",
    "  \n",
    "**Why is the decay rate important?**\n",
    "\n",
    "  - Stationarity: **A stationary time series has a constant mean, variance, and autocorrelation structure over time. A slowly decaying ACF can be a sign of non-stationarity**.\n",
    "  - Forecasting: Understanding the decay rate of the ACF can help in selecting appropriate forecasting models. For example, if the ACF decays slowly, a model that accounts for long-term dependencies, such as an ARIMA model, might be suitable.\n",
    "  - Model building: The decay rate of the ACF can be used to identify the order of autoregressive (AR) and moving average (MA) components in time series models.\n",
    "\n",
    "In summary, the autocorrelation function provides valuable insights into the dependence structure of a time series. By examining the decay rate of the ACF, we can gain a better understanding of the persistence and predictability of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce153c",
   "metadata": {},
   "source": [
    "## -- -- -- --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb6925",
   "metadata": {},
   "source": [
    "- for arima\n",
    "   - so integrated part means differencing\n",
    "   - first we need to make time series data stationary via differencing method\n",
    "   - then only we will combine ar and ma part to get future value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3973f",
   "metadata": {},
   "source": [
    "Yes, exactly! The **Integrated** part of ARIMA refers to **differencing**, and its primary role is to make the time series **stationary**. Here's the correct flow:\n",
    "\n",
    "### Steps in ARIMA:\n",
    "\n",
    "1. **Check for Stationarity**: \n",
    "   - Before applying the AR and MA components, you first need to check if the time series is **stationary** (i.e., it has constant mean, variance, and no seasonality or trend).\n",
    "   - If the time series is **not stationary**, this is where the **Integrated (I)** part comes in.\n",
    "\n",
    "2. **Apply Differencing**:\n",
    "   - Differencing helps to remove trends or seasonality, turning a non-stationary series into a stationary one.\n",
    "   - Differencing essentially subtracts the previous value from the current value:\n",
    "     $$\n",
    "     y'_t = y_t - y_{t-1}\n",
    "     $$\n",
    "   - If one differencing is not enough, you can apply differencing multiple times (as dictated by the **d** value in ARIMA).\n",
    "   \n",
    "   - For example, if **d = 1**, the series is differenced once; if **d = 2**, the series is differenced twice (i.e., difference of the differences).\n",
    "\n",
    "3. **Combine AR (AutoRegressive) and MA (Moving Average)**:\n",
    "   - Once the time series is stationary, you can apply the **AR** (AutoRegressive) part, which models the relationship between the current value and its past values (lags).\n",
    "   - Then, you apply the **MA** (Moving Average) part, which models the relationship between the current value and past errors or residuals.\n",
    "   \n",
    "   The general ARIMA model equation would be applied on the **differenced** series:\n",
    "\n",
    "   $$\n",
    "   y'_t = \\sum_{i=1}^{p} \\phi_i y'_{t-i} + \\sum_{j=1}^{q} \\theta_j \\epsilon_{t-j} + \\epsilon_t\n",
    "   $$\n",
    "\n",
    "4. **Predict Future Values**:\n",
    "   - Once the AR and MA parts are modeled, you can use the model to predict future values of the series.\n",
    "   - After modeling the differenced data, you can revert it back to the original scale by adding back the differenced values (if needed).\n",
    "\n",
    "### Summary:\n",
    "- **Differencing (I)** makes the series stationary by removing trends or seasonality.\n",
    "- After making the data stationary, you apply **AR (p)** and **MA (q)** components to model the relationships between the values and residuals of the time series.\n",
    "- Once both components are combined, you get the future predictions of the time series.\n",
    "\n",
    "Thus, **differencing is the key first step** in making the data ready for ARIMA's AR and MA components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff7085",
   "metadata": {},
   "source": [
    "# --- --- --- --- --\n",
    "\n",
    "- Exponential smoothing is a family of forecasting methods used to predict future values of a time series. These methods assign exponentially decreasing weights to past observations, giving more recent data greater importance.\n",
    "\n",
    "  - Simple exponential smoothing: Suitable for stationary time series with no trend or seasonality.\n",
    "     - $F_{t+1}$ = $\\alpha A_t + (1-\\alpha)F_t$\n",
    "     -  **$\\alpha$ range from zero to one**\n",
    "     - if alpha is zero, Places more weight on recent observations\n",
    "     - if alpha is one, places more weight to historical data\n",
    "     - finding alpha\n",
    "        - hit and trial method, observer model performance\n",
    "        - omptimzation:Grid Search: use optimization techniques to find the best alpha that minimizes the error of the forecast\n",
    "        - The model with the lowest AIC or BIC will typically provide the best value of alph\n",
    "  - Holt's linear method: Suitable for time series with a linear trend.\n",
    "     - Forecast for period $t+1: Ft+1 = αYt + (1-α)(Ft + Bt)$\n",
    "       - Level component: $Lt = αYt + (1-α)(Lt-1 + Bt-1)$\n",
    "       - Trend component: $Bt = β(Lt - Lt-1) + (1-β)Bt-1$|\n",
    "       - Ft is the forecast for period t\n",
    "         - Yt is the actual value for period t\n",
    "         - Lt is the level component (the average value of the series)\n",
    "         - Bt is the trend component (the rate of change of the series)\n",
    "         - α and β are smoothing parameters that control the weight given to the current observation and the previous forecast.\n",
    "  - Holt's method with damped trend: Suitable for time series with a linear trend that is expected to slow down over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c737dd9",
   "metadata": {},
   "source": [
    "# -- -- -- -- -- --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff0767",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "**Regression Def**\n",
    "\n",
    "- In linear regression, the relationship between the independent variables (inputs) and the dependent variable (output) is modeled as a linear equation.\n",
    "- The aim is to fit a straight line that best represents the data by minimizing the sum of squared errors (the difference between the observed and predicted values). \n",
    "- This process adjusts the line so that the total squared difference between actual and predicted values is as small as possible, ensuring the best fit for the data.\n",
    "- when there are outliers in the data, Mean Absolute Error (MAE) can be a better metric than the sum of squared errors (SSE) or Mean Squared Error (MSE). This is because MSE/SSE squares the errors, making large errors (like those caused by outliers) disproportionately impactful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6584cf6a",
   "metadata": {},
   "source": [
    "**key assumption in linear regression**:\n",
    "\n",
    " - Linearity: The relationship between the independent variables and the dependent variable is linear.\n",
    " - Independence: Observations are independent of each other, meaning no autocorrelation.\n",
    " - Homoscedasticity: The variance of the errors (residuals) is constant across all levels of the independent variables.\n",
    " - No multicollinearity: Independent variables should not be highly correlated with each other.\n",
    " - Normality of residuals: The residuals (errors) should be normally distributed for reliable hypothesis testing and confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a3aa7",
   "metadata": {},
   "source": [
    "**Sigmoid function**\n",
    "\n",
    "It is a mathematical function commonly used in logistic regression and neural networks to transform values into probabilities. It has an \"S\"-shaped curve, and the formula is:\n",
    "\n",
    "$$σ(z)= 1/(1+e^z)$$\n",
    " \n",
    " \n",
    "Where:\n",
    "\n",
    "\n",
    "- z is the input (a linear combination of features).\n",
    "- e is the mathematical constant approximately equal to 2.718.\n",
    "\n",
    "Key Properties:\n",
    "  - The output range is between 0 and 1, making it suitable for modeling probabilities.\n",
    "  - For large positive values of z, the sigmoid approaches 1.\n",
    "  - For large negative values of z, the sigmoid approaches 0.\n",
    "  - At z=0, the sigmoid value is 0.5.\n",
    "  \n",
    "This function helps logistic regression convert any real number into a probability for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6922b",
   "metadata": {},
   "source": [
    "**What is multicollinearity, and how do you detect it**? --- --- --- ---\n",
    "\n",
    "Multicollinearity occurs when independent variables are highly correlated. Detection methods include looking at the Variance Inflation Factor (VIF) or correlation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d2258d",
   "metadata": {},
   "source": [
    "**Lasso (L1), Ridge (L2), and Elastic Net Regularization** -- -- -- -- --\n",
    "\n",
    "- Overfitting occurs when a model becomes overly complex and learns the training data too well, leading to poor performance on new, unseen data. \n",
    "- **Regularization techniques help to address this by adding a penalty term to the loss function. This penalty term discourages the model from assigning large weights to features, which can help prevent overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712544c1",
   "metadata": {},
   "source": [
    "- **Lasso Regression (L1 Regularization)**\n",
    "  - The main purpose of Lasso is to improve prediction accuracy and interpretability by shrinking some regression coefficients to exactly zero, effectively performing feature selection.\n",
    "  - $$ Loss = Original Loss + λ * Σ_{i=1}^{n} |w_i|$$\n",
    "  - $$ Loss = MSE + λ * Σ|βi|$$\n",
    "  \n",
    "- **Ridge Regression (L2 Regularization)**\n",
    "  - L2 regularization adds the squared value of the coefficients to the loss function. \n",
    "  - This method tends to keep all features but reduces their impact by shrinking their values.\n",
    "  -  Ridge regression shrinks all weights towards zero but rarely sets them to exactly zero. This can help to reduce the variance of the model and prevent overfitting.\n",
    "  - $$Loss = Original Loss + λ₂ * Σ_{i=1}^{n} w_i²$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ddebd",
   "metadata": {},
   "source": [
    "- **Elastic Net**\n",
    "  - Elastic Net combines the benefits of both Lasso and Ridge. It can shrink some weights to zero (like Lasso) and reduce the variance of the model (like Ridge).\n",
    "  - **$$Loss = Original Loss + λ₁ * Σ_{i=1}^{n} |w_i| + λ₂ * Σ_{i=1}^{n} w_i²$$**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5133841",
   "metadata": {},
   "source": [
    "- **Choosing the Right Regularization Technique**:\n",
    "\n",
    "  - Lasso: If you believe that many features are irrelevant, Lasso can be a good choice for feature selection.\n",
    "  - Ridge: If you believe that many features are relevant but have correlated effects, Ridge can be a good choice for reducing the variance of the model.\n",
    "  - Elastic Net: If you're unsure which regularization technique to use, Elastic Net offers a flexible approach that can combine the benefits of both Lasso and Ridge.\n",
    "  \n",
    "- **L1, L2, and Elastic Net regularization can be used in both linear regression and logistic regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4f4cee",
   "metadata": {},
   "source": [
    "**Difference b/w $R^2$ and adjusted $R^2$** --- -- -- -- ---\n",
    "- R-squared measures the overall fit of a model, while adjusted R-squared provides a more accurate assessment of the model's fit after considering the number of predictors. Adjusted R-squared is often used to prevent overfitting, as it penalizes models with too many unnecessary predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8efa3f",
   "metadata": {},
   "source": [
    "#### How would you handle a dataset with outliers when performing regression? --- -- -- ---\n",
    "\n",
    "- Outliers can significantly impact the results of a regression analysis, leading to biased estimates and reduced model accuracy. Here are some common strategies to handle outliers in regression\n",
    "\n",
    "  - 1. Identification:\n",
    "\n",
    "     - Visual inspection: Create plots like scatter plots, histograms, or box plots to visually identify outliers.\n",
    "     - Statistical methods: Use statistical measures like the Z-score or IQR (Interquartile Range) to identify points that deviate significantly from the rest of the data.\n",
    "        - Z score:  statistical measure that quantifies the number of standard deviations a data point is from the mean of a dataset. \n",
    "          - $Z = \\frac{(x - \\mu)}{\\sigma}$\n",
    "          - z value higher $+-3$ is considered as outlier data point\n",
    "      \n",
    "\n",
    "        - The Interquartile Range (IQR) is a measure of statistical dispersion that is calculated as the difference between the third quartile (Q3) and the first quartile (Q1) of a dataset\n",
    "         - **Determine the outlier boundaries**:\n",
    "           - Lower bound: Q1 - 1.5 * IQR\n",
    "           - Upper bound: Q3 + 1.5 * IQR\n",
    "  \n",
    "  - 2. Treatment\n",
    "       - Transformation\n",
    "          - Log transformation: If the data is skewed, a log transformation can help to normalize the distribution and reduce the impact of outliers.\n",
    "          - Winsorization: This involves replacing outliers with the nearest non-outlier value\n",
    "       - Removal:\n",
    "          - Careful Removal: sure , that the value is not possible\n",
    "          - Trimming: This involves removing a fixed percentage of the most extreme values from both ends of the data.\n",
    "       - Model Selection:\n",
    "         - Consider non-parametric methods: Methods like Support Vector Machines (SVM) or random forests are less sensitive to outliers than linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09218ad",
   "metadata": {},
   "source": [
    "### Stepwise Regression -- -- -- -- --\n",
    "\n",
    "- Stepwise regression is a statistical method used for selecting a subset of independent variables from a larger set to include in a regression model. It's a greedy algorithm that adds or removes predictors one at a time based on a specific criterion, such as p-values or information criteria (like AIC or BIC).\n",
    "\n",
    "**Types of Stepwise Regression**:\n",
    "\n",
    "- Forward selection: Starts with no predictors and adds one at a time based on the criterion.\n",
    "- Backward elimination: Starts with all predictors and removes one at a time based on the criterion.\n",
    "- Stepwise selection: A combination of forward and backward selection, where predictors can be added or removed at each step.\n",
    "\n",
    "**How It Works**:\n",
    "\n",
    "- Start with an initial model: This can be a model with no predictors or with all predictors.\n",
    "- Add or remove predictors: Based on the selected criterion, a predictor is either added to or removed from the model.\n",
    "- Evaluate the model: The performance of the model is evaluated using the chosen criterion.\n",
    "- Repeat: Steps 2 and 3 are repeated until a stopping criterion is met (e.g., maximum number of steps, minimum p-value).\n",
    "\n",
    "**Common Criteria**:\n",
    "\n",
    " - P-values: Predictors with p-values below a certain threshold are retained, while those above the threshold are removed.\n",
    "- Information criteria: AIC (Akaike Information Criterion) or BIC (Bayesian Information Criterion) penalize models with more predictors, helping to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d1d55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
